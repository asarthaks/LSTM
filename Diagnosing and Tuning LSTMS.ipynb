{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Diagnose and Tune LSTMs\n",
    "## 1) Evaluating LSTM Models Robustly\n",
    "#### Split data into test and train sets and fit model multiple times.\n",
    "## 2) Diagnosing Underfitting and Overfitting\n",
    "## 3) Tune Problem Framing\n",
    "## 4) Tune Model Structure\n",
    "## 5) Tune Learning Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return training data\n",
    "def get_train():\n",
    "    seq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "    seq = array(seq)\n",
    "    X, y = seq[:, 0], seq[:, 1]\n",
    "    X = X.reshape((len(X), 1, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return validation data\n",
    "def get_val():\n",
    "    seq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "    seq = array(seq)\n",
    "    X, y = seq[:, 0], seq[:, 1]\n",
    "    X = X.reshape((len(X), 1, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostics plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sarthak/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1, 1)))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sarthak/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 572ms/step - loss: 0.1004 - val_loss: 0.5905\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.0994 - val_loss: 0.5871\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0984 - val_loss: 0.5831\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0972 - val_loss: 0.5794\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.5756\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0949 - val_loss: 0.5717\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.5678\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0925 - val_loss: 0.5639\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.5600\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.5560\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.5521\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0878 - val_loss: 0.5481\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.5442\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 927us/step - loss: 0.0855 - val_loss: 0.5402\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.5362\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.5323\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.5283\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.5243\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.0798 - val_loss: 0.5204\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 772us/step - loss: 0.0786 - val_loss: 0.5164\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 518us/step - loss: 0.0775 - val_loss: 0.5124\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.0764 - val_loss: 0.5085\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.5045\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 881us/step - loss: 0.0742 - val_loss: 0.5005\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.0731 - val_loss: 0.4966\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.4926\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 515us/step - loss: 0.0709 - val_loss: 0.4887\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.4848\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 517us/step - loss: 0.0688 - val_loss: 0.4808\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.4769\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.4730\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 511us/step - loss: 0.0656 - val_loss: 0.4691\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 845us/step - loss: 0.0646 - val_loss: 0.4652\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0636 - val_loss: 0.4613\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0626 - val_loss: 0.4574\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0616 - val_loss: 0.4535\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0606 - val_loss: 0.4496\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0596 - val_loss: 0.4458\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.4419\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.4380\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.4342\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.4304\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.0548 - val_loss: 0.4266\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 883us/step - loss: 0.0539 - val_loss: 0.4228\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 436us/step - loss: 0.0530 - val_loss: 0.4190\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0520 - val_loss: 0.4152\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.4114\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 533us/step - loss: 0.0503 - val_loss: 0.4076\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0494 - val_loss: 0.4039\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.4002\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.3964\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.0468 - val_loss: 0.3927\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 680us/step - loss: 0.0459 - val_loss: 0.3890\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.3853\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0443 - val_loss: 0.3817\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.3780\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 478us/step - loss: 0.0427 - val_loss: 0.3744\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 555us/step - loss: 0.0419 - val_loss: 0.3708\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 488us/step - loss: 0.0411 - val_loss: 0.3671\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0403 - val_loss: 0.3636\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 625us/step - loss: 0.0396 - val_loss: 0.3600\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.3564\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.3529\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.3494\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.3459\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.3424\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.3389\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.3355\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 914us/step - loss: 0.0339 - val_loss: 0.3321\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.0332 - val_loss: 0.3287\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.3253\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.3220\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.3186\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.3153\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 887us/step - loss: 0.0301 - val_loss: 0.3120\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 661us/step - loss: 0.0295 - val_loss: 0.3087\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 826us/step - loss: 0.0289 - val_loss: 0.3055\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 616us/step - loss: 0.0284 - val_loss: 0.3023\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.2990\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 608us/step - loss: 0.0272 - val_loss: 0.2959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.2927\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.2896\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.2865\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.2834\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.2803\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.0242 - val_loss: 0.2773\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.2743\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.2713\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.2684\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.2655\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.2626\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2597\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.2569\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.2541\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.2513\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.2486\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.2459\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.2432\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.2405\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.2379\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X, y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=100, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfit model : This can be diagnosed from a plot where the training loss is lower than the validation loss, and the validation loss has a trend that suggests further improvements are possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(1, input_shape=(1,1)))\n",
    "model2.add(Dense(1, activation= 'linear' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model2.compile(loss= 'mae' , optimizer= 'sgd' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 291ms/step - loss: 0.2971 - val_loss: 0.7797\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2862 - val_loss: 0.7688\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 902us/step - loss: 0.2753 - val_loss: 0.7579\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 531us/step - loss: 0.2644 - val_loss: 0.7470\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 457us/step - loss: 0.2535 - val_loss: 0.7361\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 461us/step - loss: 0.2426 - val_loss: 0.7252\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 505us/step - loss: 0.2317 - val_loss: 0.7144\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2208 - val_loss: 0.7035\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2098 - val_loss: 0.6926\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.1989 - val_loss: 0.6817\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1917 - val_loss: 0.6751\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.1877 - val_loss: 0.6685\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1838 - val_loss: 0.6620\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.6554\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.6488\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 657us/step - loss: 0.1720 - val_loss: 0.6423\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.6357\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1641 - val_loss: 0.6291\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1602 - val_loss: 0.6226\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1563 - val_loss: 0.6160\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.1523 - val_loss: 0.6094\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1484 - val_loss: 0.6029\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.1445 - val_loss: 0.5963\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1406 - val_loss: 0.5897\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1375 - val_loss: 0.5875\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1370 - val_loss: 0.5853\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1366 - val_loss: 0.5831\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1361 - val_loss: 0.5808\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.1357 - val_loss: 0.5786\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1352 - val_loss: 0.5764\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 496us/step - loss: 0.1348 - val_loss: 0.5742\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 564us/step - loss: 0.1343 - val_loss: 0.5719\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.1339 - val_loss: 0.5697\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.1334 - val_loss: 0.5675\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.5653\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.1325 - val_loss: 0.5630\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 679us/step - loss: 0.1321 - val_loss: 0.5608\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 0.5586\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1312 - val_loss: 0.5564\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 0.5542\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 0.5519\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1298 - val_loss: 0.5497\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.1294 - val_loss: 0.5475\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1289 - val_loss: 0.5453\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.5430\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1280 - val_loss: 0.5408\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1276 - val_loss: 0.5386\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1271 - val_loss: 0.5364\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.5341\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1263 - val_loss: 0.5319\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1258 - val_loss: 0.5297\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.5275\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1249 - val_loss: 0.5253\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 771us/step - loss: 0.1245 - val_loss: 0.5230\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 857us/step - loss: 0.1240 - val_loss: 0.5208\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1236 - val_loss: 0.5186\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1231 - val_loss: 0.5164\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1227 - val_loss: 0.5141\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 551us/step - loss: 0.1222 - val_loss: 0.5119\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 562us/step - loss: 0.1218 - val_loss: 0.5097\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.1213 - val_loss: 0.5075\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1209 - val_loss: 0.5053\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1204 - val_loss: 0.5030\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1200 - val_loss: 0.5008\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.1195 - val_loss: 0.4986\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.1191 - val_loss: 0.4964\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1186 - val_loss: 0.4941\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.4919\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 835us/step - loss: 0.1177 - val_loss: 0.4897\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.4918\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4896\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.4917\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4895\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.4917\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 776us/step - loss: 0.1177 - val_loss: 0.4894\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 675us/step - loss: 0.1179 - val_loss: 0.4916\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4893\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1179 - val_loss: 0.4915\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.4893\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.4914\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.1176 - val_loss: 0.4892\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.1178 - val_loss: 0.4913\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1178 - val_loss: 0.4912\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 687us/step - loss: 0.1176 - val_loss: 0.4890\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.4911\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4889\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.1178 - val_loss: 0.4910\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.4888\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4910\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4887\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1177 - val_loss: 0.4909\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4886\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.4908\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4886\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.1177 - val_loss: 0.4907\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.4885\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4906\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4884\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4905\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4883\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.4904\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4882\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1176 - val_loss: 0.4903\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4881\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4903\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 932us/step - loss: 0.1173 - val_loss: 0.4880\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4902\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.4879\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1175 - val_loss: 0.4901\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.4879\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1175 - val_loss: 0.4900\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.1172 - val_loss: 0.4878\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4899\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.4877\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4898\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.4876\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.4897\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4875\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.4896\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4874\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4896\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4873\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.4895\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 776us/step - loss: 0.1171 - val_loss: 0.4872\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4894\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 914us/step - loss: 0.1171 - val_loss: 0.4872\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.4893\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.4871\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.4892\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.4870\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.4891\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1170 - val_loss: 0.4869\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.4890\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1170 - val_loss: 0.4868\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.1172 - val_loss: 0.4889\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1169 - val_loss: 0.4867\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 648us/step - loss: 0.1172 - val_loss: 0.4889\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1169 - val_loss: 0.4866\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4888\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.4865\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4887\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1169 - val_loss: 0.4865\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4886\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.4864\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.4885\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1168 - val_loss: 0.4863\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.4884\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.1168 - val_loss: 0.4862\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.4883\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1168 - val_loss: 0.4861\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.4882\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.4860\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1170 - val_loss: 0.4881\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1167 - val_loss: 0.4859\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.4881\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.4858\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.4880\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.1167 - val_loss: 0.4858\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.4879\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.1166 - val_loss: 0.4857\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1169 - val_loss: 0.4878\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1166 - val_loss: 0.4856\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 651us/step - loss: 0.1168 - val_loss: 0.4877\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 559us/step - loss: 0.1166 - val_loss: 0.4855\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.1168 - val_loss: 0.4876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.1166 - val_loss: 0.4854\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 945us/step - loss: 0.1168 - val_loss: 0.4875\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.4853\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1168 - val_loss: 0.4874\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1165 - val_loss: 0.4852\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 524us/step - loss: 0.1167 - val_loss: 0.4874\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1165 - val_loss: 0.4851\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1167 - val_loss: 0.4873\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1165 - val_loss: 0.4850\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.4872\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1165 - val_loss: 0.4850\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.4871\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.4849\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.4870\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.4848\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.1166 - val_loss: 0.4869\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.4847\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.4868\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 885us/step - loss: 0.1164 - val_loss: 0.4846\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.4867\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1163 - val_loss: 0.4845\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1165 - val_loss: 0.4867\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.4844\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1165 - val_loss: 0.4866\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 839us/step - loss: 0.1163 - val_loss: 0.4843\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1165 - val_loss: 0.4865\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.4843\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1165 - val_loss: 0.4864\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1162 - val_loss: 0.4842\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.4863\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 563us/step - loss: 0.1162 - val_loss: 0.4841\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.4862\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1162 - val_loss: 0.4840\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1164 - val_loss: 0.4861\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1162 - val_loss: 0.4839\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1164 - val_loss: 0.4860\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1161 - val_loss: 0.4838\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.4860\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1161 - val_loss: 0.4837\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.4859\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1161 - val_loss: 0.4836\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.4858\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 902us/step - loss: 0.1161 - val_loss: 0.4836\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1163 - val_loss: 0.4857\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.4835\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.4856\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 606us/step - loss: 0.1160 - val_loss: 0.4834\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1162 - val_loss: 0.4855\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.4833\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 830us/step - loss: 0.1162 - val_loss: 0.4854\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.4832\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 567us/step - loss: 0.1162 - val_loss: 0.4853\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.4831\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.1161 - val_loss: 0.4853\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1159 - val_loss: 0.4830\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1161 - val_loss: 0.4852\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1159 - val_loss: 0.4829\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 872us/step - loss: 0.1161 - val_loss: 0.4851\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.4829\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1161 - val_loss: 0.4850\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.1159 - val_loss: 0.4828\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.4849\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 908us/step - loss: 0.1158 - val_loss: 0.4827\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.4848\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1158 - val_loss: 0.4826\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.1160 - val_loss: 0.4847\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.4825\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1160 - val_loss: 0.4846\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 987us/step - loss: 0.1158 - val_loss: 0.4824\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 936us/step - loss: 0.1159 - val_loss: 0.4845\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1157 - val_loss: 0.4823\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.4845\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 863us/step - loss: 0.1157 - val_loss: 0.4822\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1159 - val_loss: 0.4844\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1157 - val_loss: 0.4821\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1159 - val_loss: 0.4843\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.4821\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.4842\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1156 - val_loss: 0.4820\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 914us/step - loss: 0.1158 - val_loss: 0.4841\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.4819\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1158 - val_loss: 0.4840\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1156 - val_loss: 0.4818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 897us/step - loss: 0.1157 - val_loss: 0.4839\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1156 - val_loss: 0.4817\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.4838\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.4816\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.4838\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.4815\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.4837\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.4814\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 462us/step - loss: 0.1156 - val_loss: 0.4836\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.4814\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 709us/step - loss: 0.1156 - val_loss: 0.4835\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.4813\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 675us/step - loss: 0.1156 - val_loss: 0.4834\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.4812\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.4833\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1154 - val_loss: 0.4811\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.4832\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.4810\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.4831\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.4809\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.4830\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.4808\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.4830\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1153 - val_loss: 0.4807\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1154 - val_loss: 0.4829\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1153 - val_loss: 0.4806\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.4828\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 449us/step - loss: 0.1152 - val_loss: 0.4806\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 869us/step - loss: 0.1154 - val_loss: 0.4827\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.4805\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.4826\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 574us/step - loss: 0.1152 - val_loss: 0.4804\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.4825\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 534us/step - loss: 0.1152 - val_loss: 0.4803\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1153 - val_loss: 0.4824\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.4802\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.4823\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1151 - val_loss: 0.4801\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 515us/step - loss: 0.1153 - val_loss: 0.4823\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.4800\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1152 - val_loss: 0.4822\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1151 - val_loss: 0.4799\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 0.4821\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.4799\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 616us/step - loss: 0.1152 - val_loss: 0.4820\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1150 - val_loss: 0.4798\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.1152 - val_loss: 0.4819\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 958us/step - loss: 0.1150 - val_loss: 0.4797\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 624us/step - loss: 0.1151 - val_loss: 0.4818\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1150 - val_loss: 0.4796\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.4817\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model2.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfit model : less number of cells | a model may be underfit if performance on the training set is better than the validation set and performance has leveled off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history[ 'loss' ])\n",
    "pyplot.plot(history.history[ 'val_loss'])\n",
    "pyplot.title( 'model train vs validation loss' )\n",
    "pyplot.ylabel( 'loss' )\n",
    "pyplot.xlabel( 'epoch' )\n",
    "pyplot.legend([ 'train' , 'validation' ], loc= 'upper right' )\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(10, input_shape=(1,1)))\n",
    "model3.add(Dense(1, activation= 'linear' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model3.compile(loss= 'mse' , optimizer= 'adam' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 2s 331ms/step - loss: 0.1136 - val_loss: 0.6822\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.1126 - val_loss: 0.6783\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1114 - val_loss: 0.6741\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1102 - val_loss: 0.6699\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1090 - val_loss: 0.6656\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1077 - val_loss: 0.6613\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.1065 - val_loss: 0.6570\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.1052 - val_loss: 0.6526\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 480us/step - loss: 0.1040 - val_loss: 0.6483\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1027 - val_loss: 0.6439\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 525us/step - loss: 0.1015 - val_loss: 0.6396\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.1002 - val_loss: 0.6353\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.0990 - val_loss: 0.6309\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 624us/step - loss: 0.0978 - val_loss: 0.6267\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0966 - val_loss: 0.6224\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0954 - val_loss: 0.6181\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 715us/step - loss: 0.0942 - val_loss: 0.6139\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.6097\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0918 - val_loss: 0.6055\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.6013\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.5971\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.5930\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0872 - val_loss: 0.5889\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.5848\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.5807\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0839 - val_loss: 0.5767\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0828 - val_loss: 0.5726\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0817 - val_loss: 0.5686\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.5646\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.5606\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.5566\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 857us/step - loss: 0.0774 - val_loss: 0.5527\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.5488\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.5449\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.5410\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 987us/step - loss: 0.0733 - val_loss: 0.5371\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.5332\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 485us/step - loss: 0.0713 - val_loss: 0.5294\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.5256\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.5218\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.0684 - val_loss: 0.5180\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.5143\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.5105\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.5068\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0647 - val_loss: 0.5031\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0638 - val_loss: 0.4994\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0628 - val_loss: 0.4958\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0620 - val_loss: 0.4921\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.4884\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 475us/step - loss: 0.0602 - val_loss: 0.4848\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0593 - val_loss: 0.4812\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0585 - val_loss: 0.4776\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 864us/step - loss: 0.0576 - val_loss: 0.4740\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.4704\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.4668\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.4633\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.0543 - val_loss: 0.4598\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0535 - val_loss: 0.4563\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 841us/step - loss: 0.0527 - val_loss: 0.4528\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.4493\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0511 - val_loss: 0.4458\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.4423\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.0496 - val_loss: 0.4389\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.4354\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.4320\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.0473 - val_loss: 0.4286\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.4252\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.0458 - val_loss: 0.4218\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.4184\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 632us/step - loss: 0.0444 - val_loss: 0.4151\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.0437 - val_loss: 0.4117\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.4084\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.4051\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.4018\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.3985\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 809us/step - loss: 0.0404 - val_loss: 0.3952\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 824us/step - loss: 0.0397 - val_loss: 0.3919\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.3887\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 938us/step - loss: 0.0384 - val_loss: 0.3854\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.3822\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.3790\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.3758\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.3726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.3695\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.0348 - val_loss: 0.3663\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.3632\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.3601\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 651us/step - loss: 0.0332 - val_loss: 0.3570\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.3539\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0321 - val_loss: 0.3508\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.3478\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.3447\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 635us/step - loss: 0.0305 - val_loss: 0.3417\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.3387\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.3357\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.3328\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0286 - val_loss: 0.3299\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.3269\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.3240\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.3212\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.3183\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.3155\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.3126\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 697us/step - loss: 0.0255 - val_loss: 0.3099\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.3071\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3043\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3016\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 821us/step - loss: 0.0239 - val_loss: 0.2989\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.2962\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.2935\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.2909\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.2883\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.2857\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.2831\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 861us/step - loss: 0.0215 - val_loss: 0.2806\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.2780\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.2755\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.2731\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.2706\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.2682\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.2658\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.2634\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 858us/step - loss: 0.0192 - val_loss: 0.2611\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.2588\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.2565\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.2542\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.2520\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.2498\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.2476\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.2454\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.2433\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.2412\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.2391\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2370\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.2350\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2330\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 733us/step - loss: 0.0163 - val_loss: 0.2310\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.2291\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.2272\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.2253\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.2234\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.2216\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.2198\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.2180\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 904us/step - loss: 0.0151 - val_loss: 0.2163\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.2145\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0149 - val_loss: 0.2128\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 856us/step - loss: 0.0148 - val_loss: 0.2112\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.2095\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2079\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.2063\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.2048\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2032\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.2017\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.2002\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1988\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1973\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1959\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1945\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 481us/step - loss: 0.0137 - val_loss: 0.1932\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1918\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1905\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1893\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 524us/step - loss: 0.0134 - val_loss: 0.1880\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.1868\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1843\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1832\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 774us/step - loss: 0.0131 - val_loss: 0.1820\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1809\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.0130 - val_loss: 0.1798\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1787\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1777\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1766\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1756\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1746\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.1736\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1727\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1717\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1708\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 675us/step - loss: 0.0126 - val_loss: 0.1699\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1690\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1682\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1673\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1665\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1657\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1649\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1641\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1633\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1626\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1618\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1611\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1604\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1597\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1590\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1583\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.1577\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1570\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1564\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0120 - val_loss: 0.1557\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1551\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1545\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 742us/step - loss: 0.0119 - val_loss: 0.1539\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1533\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1528\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1522\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.1516\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1511\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1505\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1500\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 894us/step - loss: 0.0117 - val_loss: 0.1495\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1489\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1484\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 560us/step - loss: 0.0116 - val_loss: 0.1479\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1474\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 744us/step - loss: 0.0116 - val_loss: 0.1469\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1464\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1460\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1455\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 702us/step - loss: 0.0115 - val_loss: 0.1450\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.0114 - val_loss: 0.1445\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1441\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1436\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1432\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 491us/step - loss: 0.0113 - val_loss: 0.1427\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.1423\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.0113 - val_loss: 0.1418\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.0113 - val_loss: 0.1414\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1409\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.0112 - val_loss: 0.1405\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1401\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 508us/step - loss: 0.0111 - val_loss: 0.1396\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 920us/step - loss: 0.0111 - val_loss: 0.1392\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 603us/step - loss: 0.0111 - val_loss: 0.1388\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 481us/step - loss: 0.0111 - val_loss: 0.1384\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.0110 - val_loss: 0.1379\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 497us/step - loss: 0.0110 - val_loss: 0.1375\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.0110 - val_loss: 0.1371\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 455us/step - loss: 0.0110 - val_loss: 0.1367\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 511us/step - loss: 0.0109 - val_loss: 0.1363\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 465us/step - loss: 0.0109 - val_loss: 0.1359\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1355\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.0108 - val_loss: 0.1351\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.0108 - val_loss: 0.1346\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 464us/step - loss: 0.0108 - val_loss: 0.1342\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.0108 - val_loss: 0.1338\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 497us/step - loss: 0.0107 - val_loss: 0.1334\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 465us/step - loss: 0.0107 - val_loss: 0.1330\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 558us/step - loss: 0.0107 - val_loss: 0.1326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.1322\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 646us/step - loss: 0.0106 - val_loss: 0.1318\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1314\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1310\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 909us/step - loss: 0.0105 - val_loss: 0.1306\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1302\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.1298\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.1294\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1290\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1286\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1282\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1278\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1274\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.0103 - val_loss: 0.1270\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1267\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 665us/step - loss: 0.0102 - val_loss: 0.1263\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 664us/step - loss: 0.0102 - val_loss: 0.1259\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1255\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1251\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 489us/step - loss: 0.0101 - val_loss: 0.1247\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1243\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 966us/step - loss: 0.0101 - val_loss: 0.1239\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1235\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 898us/step - loss: 0.0100 - val_loss: 0.1231\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.0100 - val_loss: 0.1227\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 573us/step - loss: 0.0100 - val_loss: 0.1223\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.0099 - val_loss: 0.1219\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 533us/step - loss: 0.0099 - val_loss: 0.1215\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1211\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 559us/step - loss: 0.0099 - val_loss: 0.1207\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1203\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 484us/step - loss: 0.0098 - val_loss: 0.1199\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 818us/step - loss: 0.0098 - val_loss: 0.1195\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.0097 - val_loss: 0.1191\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 492us/step - loss: 0.0097 - val_loss: 0.1187\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1183\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1179\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 859us/step - loss: 0.0096 - val_loss: 0.1175\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 788us/step - loss: 0.0096 - val_loss: 0.1171\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0096 - val_loss: 0.1167\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1163\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1159\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1155\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1151\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1147\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.0094 - val_loss: 0.1143\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1139\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1135\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1131\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 898us/step - loss: 0.0093 - val_loss: 0.1127\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1123\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1119\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1115\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1111\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1107\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1103\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1099\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1095\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 910us/step - loss: 0.0090 - val_loss: 0.1091\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 981us/step - loss: 0.0090 - val_loss: 0.1087\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1083\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1079\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 893us/step - loss: 0.0089 - val_loss: 0.1075\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1071\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1067\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1063\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.1059\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1054\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1050\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1046\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1042\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1038\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1034\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1030\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 654us/step - loss: 0.0086 - val_loss: 0.1026\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1022\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1018\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1014\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1010\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1006\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1002\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0998\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 874us/step - loss: 0.0084 - val_loss: 0.0994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0990\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0986\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0982\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0978\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0974\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 654us/step - loss: 0.0082 - val_loss: 0.0970\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0966\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0962\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0958\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0953\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 490us/step - loss: 0.0081 - val_loss: 0.0949\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0945\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 731us/step - loss: 0.0080 - val_loss: 0.0941\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 725us/step - loss: 0.0080 - val_loss: 0.0937\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0933\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 568us/step - loss: 0.0079 - val_loss: 0.0929\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 648us/step - loss: 0.0079 - val_loss: 0.0925\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 923us/step - loss: 0.0079 - val_loss: 0.0921\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0917\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.0078 - val_loss: 0.0913\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0909\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0905\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0901\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 902us/step - loss: 0.0077 - val_loss: 0.0897\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0893\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 536us/step - loss: 0.0076 - val_loss: 0.0889\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0076 - val_loss: 0.0885\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 921us/step - loss: 0.0076 - val_loss: 0.0881\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.0075 - val_loss: 0.0877\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 604us/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.0075 - val_loss: 0.0869\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0865\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0861\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.0074 - val_loss: 0.0857\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 522us/step - loss: 0.0074 - val_loss: 0.0853\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 917us/step - loss: 0.0073 - val_loss: 0.0849\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.0073 - val_loss: 0.0845\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0841\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 899us/step - loss: 0.0072 - val_loss: 0.0836\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0832\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 743us/step - loss: 0.0072 - val_loss: 0.0828\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0824\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0820\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 742us/step - loss: 0.0071 - val_loss: 0.0816\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0812\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0808\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0804\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0800\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0070 - val_loss: 0.0796\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0792\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0788\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0784\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0780\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0776\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0772\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0768\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0764\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0760\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.0067 - val_loss: 0.0756\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0752\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0748\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 507us/step - loss: 0.0066 - val_loss: 0.0744\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0740\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0736\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0732\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0729\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0725\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0721\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0717\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 491us/step - loss: 0.0063 - val_loss: 0.0713\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0709\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 513us/step - loss: 0.0063 - val_loss: 0.0705\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 867us/step - loss: 0.0063 - val_loss: 0.0701\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.0062 - val_loss: 0.0697\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0693\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0689\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0685\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 484us/step - loss: 0.0061 - val_loss: 0.0681\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0677\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0673\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.0060 - val_loss: 0.0669\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 933us/step - loss: 0.0060 - val_loss: 0.0665\n",
      "Epoch 415/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0661\n",
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0657\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.0059 - val_loss: 0.0654\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0650\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 823us/step - loss: 0.0059 - val_loss: 0.0646\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 870us/step - loss: 0.0058 - val_loss: 0.0642\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0638\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.0058 - val_loss: 0.0634\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0630\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0057 - val_loss: 0.0626\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.0057 - val_loss: 0.0622\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0618\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0615\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0611\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 506us/step - loss: 0.0056 - val_loss: 0.0607\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0055 - val_loss: 0.0603\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 492us/step - loss: 0.0055 - val_loss: 0.0599\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0595\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0591\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0588\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0584\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0580\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 715us/step - loss: 0.0053 - val_loss: 0.0576\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0572\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0568\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0565\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0561\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0557\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0553\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 550us/step - loss: 0.0051 - val_loss: 0.0549\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0546\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 494us/step - loss: 0.0051 - val_loss: 0.0542\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0538\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0534\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0531\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 644us/step - loss: 0.0050 - val_loss: 0.0527\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0049 - val_loss: 0.0523\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.0049 - val_loss: 0.0519\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0516\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0049 - val_loss: 0.0512\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0508\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0504\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0501\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0497\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 564us/step - loss: 0.0047 - val_loss: 0.0493\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0490\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0486\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0482\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0478\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0475\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0471\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0468\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 787us/step - loss: 0.0045 - val_loss: 0.0464\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0460\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0457\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0453\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0449\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 682us/step - loss: 0.0043 - val_loss: 0.0446\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0442\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0439\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0435\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.0042 - val_loss: 0.0431\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0428\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0424\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0421\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0417\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 720us/step - loss: 0.0041 - val_loss: 0.0414\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0410\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.0040 - val_loss: 0.0407\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0403\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0400\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0396\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0393\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0389\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 662us/step - loss: 0.0039 - val_loss: 0.0386\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0382\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0379\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0376\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0372\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0369\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0365\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0362\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 897us/step - loss: 0.0036 - val_loss: 0.0355\n",
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0352\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0349\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0345\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0342\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 785us/step - loss: 0.0035 - val_loss: 0.0339\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0335\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0332\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0329\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 522us/step - loss: 0.0034 - val_loss: 0.0326\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0322\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0319\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 496us/step - loss: 0.0033 - val_loss: 0.0316\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0313\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.0033 - val_loss: 0.0309\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0306\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0303\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 625us/step - loss: 0.0032 - val_loss: 0.0300\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0297\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 664us/step - loss: 0.0031 - val_loss: 0.0294\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0291\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.0031 - val_loss: 0.0287\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 556us/step - loss: 0.0031 - val_loss: 0.0284\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0281\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0278\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0275\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0272\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 684us/step - loss: 0.0029 - val_loss: 0.0269\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0266\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0263\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.0260\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0257\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.0028 - val_loss: 0.0254\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0251\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0248\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0245\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0243\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0240\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0237\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0234\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0231\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0228\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 710us/step - loss: 0.0026 - val_loss: 0.0226\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0223\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0220\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0217\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 731us/step - loss: 0.0025 - val_loss: 0.0214\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0212\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0209\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0206\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0204\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0201\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 675us/step - loss: 0.0024 - val_loss: 0.0198\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0196\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0193\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0191\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0188\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0185\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0183\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0180\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0178\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0175\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0173\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0171\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0168\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0166\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0163\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0161\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 559us/step - loss: 0.0020 - val_loss: 0.0159\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 956us/step - loss: 0.0020 - val_loss: 0.0156\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0154\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0152\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0149\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0147\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0145\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0143\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0140\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0138\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0136\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0134\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0132\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0130\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 705us/step - loss: 0.0017 - val_loss: 0.0125\n",
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0123\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0121\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0119\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0117\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0115\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 507us/step - loss: 0.0016 - val_loss: 0.0113\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0111\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0109\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 527us/step - loss: 0.0015 - val_loss: 0.0107\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0105\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0104\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0102\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0100\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 901us/step - loss: 0.0015 - val_loss: 0.0098\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0096\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 474us/step - loss: 0.0014 - val_loss: 0.0094\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0093\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0091\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 519us/step - loss: 0.0014 - val_loss: 0.0089\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0088\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0086\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0084\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0083\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0081\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.0013 - val_loss: 0.0079\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0078\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 566us/step - loss: 0.0012 - val_loss: 0.0075\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0072\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 743us/step - loss: 0.0012 - val_loss: 0.0070\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0069\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 496us/step - loss: 0.0012 - val_loss: 0.0067\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0064\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0063\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0061\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0060\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0059\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0057\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.0010 - val_loss: 0.0056\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0055\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0053\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 898us/step - loss: 9.9616e-04 - val_loss: 0.0052\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 674us/step - loss: 9.8274e-04 - val_loss: 0.0051\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.6944e-04 - val_loss: 0.0050\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 945us/step - loss: 9.5627e-04 - val_loss: 0.0049\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.4322e-04 - val_loss: 0.0047\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.3031e-04 - val_loss: 0.0046\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.1751e-04 - val_loss: 0.0045\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 615us/step - loss: 9.0484e-04 - val_loss: 0.0044\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.9229e-04 - val_loss: 0.0043\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.7986e-04 - val_loss: 0.0042\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.6756e-04 - val_loss: 0.0041\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.5538e-04 - val_loss: 0.0040\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.4332e-04 - val_loss: 0.0038\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 617us/step - loss: 8.3139e-04 - val_loss: 0.0037\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.1958e-04 - val_loss: 0.0036\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0788e-04 - val_loss: 0.0035\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 974us/step - loss: 7.9632e-04 - val_loss: 0.0034\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.8487e-04 - val_loss: 0.0034\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.7354e-04 - val_loss: 0.0033\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.6233e-04 - val_loss: 0.0032\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.5125e-04 - val_loss: 0.0031\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 786us/step - loss: 7.4028e-04 - val_loss: 0.0030\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.2943e-04 - val_loss: 0.0029\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.1870e-04 - val_loss: 0.0028\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 902us/step - loss: 7.0808e-04 - val_loss: 0.0027\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 975us/step - loss: 6.9759e-04 - val_loss: 0.0026\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.8721e-04 - val_loss: 0.0026\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.7695e-04 - val_loss: 0.0025\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6680e-04 - val_loss: 0.0024\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.5677e-04 - val_loss: 0.0023\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.4686e-04 - val_loss: 0.0023\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.3705e-04 - val_loss: 0.0022\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.2736e-04 - val_loss: 0.0021\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.1779e-04 - val_loss: 0.0020\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.0833e-04 - val_loss: 0.0020\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.9897e-04 - val_loss: 0.0019\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 708us/step - loss: 5.8973e-04 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.8060e-04 - val_loss: 0.0018\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 634us/step - loss: 5.7159e-04 - val_loss: 0.0017\n",
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.6268e-04 - val_loss: 0.0016\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 810us/step - loss: 5.5388e-04 - val_loss: 0.0016\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.4519e-04 - val_loss: 0.0015\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3660e-04 - val_loss: 0.0015\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.2812e-04 - val_loss: 0.0014\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1975e-04 - val_loss: 0.0014\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1149e-04 - val_loss: 0.0013\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 708us/step - loss: 5.0333e-04 - val_loss: 0.0013\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.9527e-04 - val_loss: 0.0012\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 565us/step - loss: 4.8732e-04 - val_loss: 0.0012\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.7947e-04 - val_loss: 0.0011\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.7173e-04 - val_loss: 0.0011\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 906us/step - loss: 4.6408e-04 - val_loss: 0.0010\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.5654e-04 - val_loss: 9.6742e-04\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4909e-04 - val_loss: 9.2457e-04\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.4175e-04 - val_loss: 8.8297e-04\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.3450e-04 - val_loss: 8.4258e-04\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2736e-04 - val_loss: 8.0341e-04\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2030e-04 - val_loss: 7.6543e-04\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.1335e-04 - val_loss: 7.2863e-04\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 908us/step - loss: 4.0649e-04 - val_loss: 6.9301e-04\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9973e-04 - val_loss: 6.5853e-04\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 890us/step - loss: 3.9306e-04 - val_loss: 6.2520e-04\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.8648e-04 - val_loss: 5.9298e-04\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8000e-04 - val_loss: 5.6188e-04\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7360e-04 - val_loss: 5.3188e-04\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.6730e-04 - val_loss: 5.0295e-04\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 884us/step - loss: 3.6109e-04 - val_loss: 4.7510e-04\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 488us/step - loss: 3.5497e-04 - val_loss: 4.4831e-04\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4894e-04 - val_loss: 4.2256e-04\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 896us/step - loss: 3.4300e-04 - val_loss: 3.9782e-04\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 497us/step - loss: 3.3714e-04 - val_loss: 3.7409e-04\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 527us/step - loss: 3.3137e-04 - val_loss: 3.5135e-04\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 769us/step - loss: 3.2568e-04 - val_loss: 3.2960e-04\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 509us/step - loss: 3.2008e-04 - val_loss: 3.0881e-04\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1456e-04 - val_loss: 2.8897e-04\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0912e-04 - val_loss: 2.7007e-04\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0377e-04 - val_loss: 2.5210e-04\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 807us/step - loss: 2.9850e-04 - val_loss: 2.3503e-04\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9331e-04 - val_loss: 2.1886e-04\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8820e-04 - val_loss: 2.0357e-04\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8316e-04 - val_loss: 1.8915e-04\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 830us/step - loss: 2.7821e-04 - val_loss: 1.7558e-04\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7333e-04 - val_loss: 1.6285e-04\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 877us/step - loss: 2.6853e-04 - val_loss: 1.5094e-04\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6381e-04 - val_loss: 1.3985e-04\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5916e-04 - val_loss: 1.2954e-04\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5458e-04 - val_loss: 1.2003e-04\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.5008e-04 - val_loss: 1.1128e-04\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4565e-04 - val_loss: 1.0329e-04\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 977us/step - loss: 2.4129e-04 - val_loss: 9.6035e-05\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.3700e-04 - val_loss: 8.9511e-05\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3278e-04 - val_loss: 8.3701e-05\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2863e-04 - val_loss: 7.8591e-05\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2455e-04 - val_loss: 7.4170e-05\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2054e-04 - val_loss: 7.0423e-05\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1659e-04 - val_loss: 6.7336e-05\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.1271e-04 - val_loss: 6.4898e-05\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0890e-04 - val_loss: 6.3095e-05\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0515e-04 - val_loss: 6.1914e-05\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 876us/step - loss: 2.0146e-04 - val_loss: 6.1341e-05\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.9784e-04 - val_loss: 6.1363e-05\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9427e-04 - val_loss: 6.1971e-05\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 665us/step - loss: 1.9077e-04 - val_loss: 6.3148e-05\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8733e-04 - val_loss: 6.4885e-05\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8395e-04 - val_loss: 6.7167e-05\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8063e-04 - val_loss: 6.9982e-05\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7737e-04 - val_loss: 7.3321e-05\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.7416e-04 - val_loss: 7.7168e-05\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7101e-04 - val_loss: 8.1512e-05\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 616us/step - loss: 1.6792e-04 - val_loss: 8.6343e-05\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6488e-04 - val_loss: 9.1647e-05\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6190e-04 - val_loss: 9.7413e-05\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 641us/step - loss: 1.5897e-04 - val_loss: 1.0363e-04\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5609e-04 - val_loss: 1.1029e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5326e-04 - val_loss: 1.1737e-04\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5049e-04 - val_loss: 1.2487e-04\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4777e-04 - val_loss: 1.3278e-04\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4509e-04 - val_loss: 1.4108e-04\n",
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 472us/step - loss: 1.4247e-04 - val_loss: 1.4977e-04\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3989e-04 - val_loss: 1.5883e-04\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 516us/step - loss: 1.3737e-04 - val_loss: 1.6825e-04\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 935us/step - loss: 1.3489e-04 - val_loss: 1.7803e-04\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3245e-04 - val_loss: 1.8815e-04\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3007e-04 - val_loss: 1.9860e-04\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2772e-04 - val_loss: 2.0937e-04\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 627us/step - loss: 1.2543e-04 - val_loss: 2.2045e-04\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2317e-04 - val_loss: 2.3184e-04\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2096e-04 - val_loss: 2.4351e-04\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1879e-04 - val_loss: 2.5547e-04\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1667e-04 - val_loss: 2.6771e-04\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 635us/step - loss: 1.1458e-04 - val_loss: 2.8021e-04\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1254e-04 - val_loss: 2.9296e-04\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1053e-04 - val_loss: 3.0596e-04\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 882us/step - loss: 1.0857e-04 - val_loss: 3.1920e-04\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0664e-04 - val_loss: 3.3266e-04\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0475e-04 - val_loss: 3.4634e-04\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0290e-04 - val_loss: 3.6024e-04\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0108e-04 - val_loss: 3.7434e-04\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.9305e-05 - val_loss: 3.8863e-04\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.7562e-05 - val_loss: 4.0311e-04\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.5854e-05 - val_loss: 4.1776e-04\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 514us/step - loss: 9.4181e-05 - val_loss: 4.3259e-04\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.2542e-05 - val_loss: 4.4758e-04\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.0936e-05 - val_loss: 4.6273e-04\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.9362e-05 - val_loss: 4.7802e-04\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 736us/step - loss: 8.7821e-05 - val_loss: 4.9345e-04\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.6312e-05 - val_loss: 5.0902e-04\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.4833e-05 - val_loss: 5.2471e-04\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.3386e-05 - val_loss: 5.4052e-04\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.1968e-05 - val_loss: 5.5645e-04\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.0580e-05 - val_loss: 5.7247e-04\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.9222e-05 - val_loss: 5.8860e-04\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7891e-05 - val_loss: 6.0482e-04\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.6588e-05 - val_loss: 6.2112e-04\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.5313e-05 - val_loss: 6.3751e-04\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.4065e-05 - val_loss: 6.5397e-04\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.2844e-05 - val_loss: 6.7050e-04\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.1648e-05 - val_loss: 6.8708e-04\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.0478e-05 - val_loss: 7.0373e-04\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.9334e-05 - val_loss: 7.2042e-04\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.8213e-05 - val_loss: 7.3717e-04\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.7118e-05 - val_loss: 7.5395e-04\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 620us/step - loss: 6.6045e-05 - val_loss: 7.7076e-04\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 606us/step - loss: 6.4996e-05 - val_loss: 7.8760e-04\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.3970e-05 - val_loss: 8.0447e-04\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.2967e-05 - val_loss: 8.2136e-04\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 593us/step - loss: 6.1985e-05 - val_loss: 8.3826e-04\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 741us/step - loss: 6.1025e-05 - val_loss: 8.5517e-04\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.0087e-05 - val_loss: 8.7208e-04\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.9169e-05 - val_loss: 8.8900e-04\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 984us/step - loss: 5.8271e-05 - val_loss: 9.0590e-04\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 540us/step - loss: 5.7394e-05 - val_loss: 9.2281e-04\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 816us/step - loss: 5.6536e-05 - val_loss: 9.3970e-04\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 487us/step - loss: 5.5697e-05 - val_loss: 9.5658e-04\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5.4877e-05 - val_loss: 9.7343e-04\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.4076e-05 - val_loss: 9.9026e-04\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model3.fit(X, y, epochs=800, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well fit model : This can be diagnosed from a plot where the train and validation loss decrease and stabilize around the same point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history[ 'loss' ])\n",
    "pyplot.plot(history.history[ 'val_loss' ])\n",
    "pyplot.title( 'model train vs validation loss')\n",
    "pyplot.ylabel( 'loss' )\n",
    "pyplot.xlabel( 'epoch' )\n",
    "pyplot.legend([ 'train' , 'validation' ], loc= 'upper right' )\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(10, input_shape=(1,1)))\n",
    "model4.add(Dense(1, activation= 'linear' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model4.compile(loss= 'mse' , optimizer= 'adam' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/1200\n",
      "5/5 [==============================] - 2s 363ms/step - loss: 0.1127 - val_loss: 0.6762\n",
      "Epoch 2/1200\n",
      "5/5 [==============================] - 0s 664us/step - loss: 0.1117 - val_loss: 0.6724\n",
      "Epoch 3/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.6685\n",
      "Epoch 4/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.6644\n",
      "Epoch 5/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1080 - val_loss: 0.6603\n",
      "Epoch 6/1200\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.1068 - val_loss: 0.6561\n",
      "Epoch 7/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.6519\n",
      "Epoch 8/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.6477\n",
      "Epoch 9/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1029 - val_loss: 0.6435\n",
      "Epoch 10/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.6393\n",
      "Epoch 11/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1004 - val_loss: 0.6351\n",
      "Epoch 12/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.6310\n",
      "Epoch 13/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0979 - val_loss: 0.6268\n",
      "Epoch 14/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0967 - val_loss: 0.6226\n",
      "Epoch 15/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.6185\n",
      "Epoch 16/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0942 - val_loss: 0.6144\n",
      "Epoch 17/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.6103\n",
      "Epoch 18/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0918 - val_loss: 0.6062\n",
      "Epoch 19/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.6021\n",
      "Epoch 20/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.5980\n",
      "Epoch 21/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.5940\n",
      "Epoch 22/1200\n",
      "5/5 [==============================] - 0s 699us/step - loss: 0.0871 - val_loss: 0.5900\n",
      "Epoch 23/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.5860\n",
      "Epoch 24/1200\n",
      "5/5 [==============================] - 0s 866us/step - loss: 0.0848 - val_loss: 0.5820\n",
      "Epoch 25/1200\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.0836 - val_loss: 0.5780\n",
      "Epoch 26/1200\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0825 - val_loss: 0.5740\n",
      "Epoch 27/1200\n",
      "5/5 [==============================] - 0s 761us/step - loss: 0.0814 - val_loss: 0.5701\n",
      "Epoch 28/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.5661\n",
      "Epoch 29/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.5622\n",
      "Epoch 30/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.5583\n",
      "Epoch 31/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.5544\n",
      "Epoch 32/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.5505\n",
      "Epoch 33/1200\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0749 - val_loss: 0.5467\n",
      "Epoch 34/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.5428\n",
      "Epoch 35/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.5390\n",
      "Epoch 36/1200\n",
      "5/5 [==============================] - 0s 596us/step - loss: 0.0717 - val_loss: 0.5351\n",
      "Epoch 37/1200\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.0707 - val_loss: 0.5313\n",
      "Epoch 38/1200\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.0697 - val_loss: 0.5275\n",
      "Epoch 39/1200\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.0687 - val_loss: 0.5237\n",
      "Epoch 40/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.5200\n",
      "Epoch 41/1200\n",
      "5/5 [==============================] - 0s 946us/step - loss: 0.0667 - val_loss: 0.5162\n",
      "Epoch 42/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.5124\n",
      "Epoch 43/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0647 - val_loss: 0.5087\n",
      "Epoch 44/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.5050\n",
      "Epoch 45/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0628 - val_loss: 0.5012\n",
      "Epoch 46/1200\n",
      "5/5 [==============================] - 0s 925us/step - loss: 0.0619 - val_loss: 0.4975\n",
      "Epoch 47/1200\n",
      "5/5 [==============================] - 0s 657us/step - loss: 0.0609 - val_loss: 0.4938\n",
      "Epoch 48/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.4901\n",
      "Epoch 49/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0591 - val_loss: 0.4864\n",
      "Epoch 50/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.4828\n",
      "Epoch 51/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.4791\n",
      "Epoch 52/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.4755\n",
      "Epoch 53/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0555 - val_loss: 0.4718\n",
      "Epoch 54/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.4682\n",
      "Epoch 55/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0538 - val_loss: 0.4646\n",
      "Epoch 56/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0529 - val_loss: 0.4610\n",
      "Epoch 57/1200\n",
      "5/5 [==============================] - 0s 782us/step - loss: 0.0521 - val_loss: 0.4574\n",
      "Epoch 58/1200\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0513 - val_loss: 0.4538\n",
      "Epoch 59/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.4502\n",
      "Epoch 60/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.4467\n",
      "Epoch 61/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.4431\n",
      "Epoch 62/1200\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.0480 - val_loss: 0.4395\n",
      "Epoch 63/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.4360\n",
      "Epoch 64/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.4325\n",
      "Epoch 65/1200\n",
      "5/5 [==============================] - 0s 559us/step - loss: 0.0457 - val_loss: 0.4290\n",
      "Epoch 66/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.4255\n",
      "Epoch 67/1200\n",
      "5/5 [==============================] - 0s 541us/step - loss: 0.0442 - val_loss: 0.4220\n",
      "Epoch 68/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.4185\n",
      "Epoch 69/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.4150\n",
      "Epoch 70/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.4116\n",
      "Epoch 71/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.4081\n",
      "Epoch 72/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.4047\n",
      "Epoch 73/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.4013\n",
      "Epoch 74/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0392 - val_loss: 0.3979\n",
      "Epoch 75/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.3945\n",
      "Epoch 76/1200\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.0379 - val_loss: 0.3912\n",
      "Epoch 77/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0372 - val_loss: 0.3878\n",
      "Epoch 78/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.3845\n",
      "Epoch 79/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.3812\n",
      "Epoch 80/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.3779\n",
      "Epoch 81/1200\n",
      "5/5 [==============================] - 0s 674us/step - loss: 0.0347 - val_loss: 0.3746\n",
      "Epoch 82/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.3713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.3681\n",
      "Epoch 84/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0330 - val_loss: 0.3648\n",
      "Epoch 85/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.3616\n",
      "Epoch 86/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.3584\n",
      "Epoch 87/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.3552\n",
      "Epoch 88/1200\n",
      "5/5 [==============================] - 0s 492us/step - loss: 0.0307 - val_loss: 0.3521\n",
      "Epoch 89/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.3490\n",
      "Epoch 90/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.3459\n",
      "Epoch 91/1200\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.0292 - val_loss: 0.3428\n",
      "Epoch 92/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.3397\n",
      "Epoch 93/1200\n",
      "5/5 [==============================] - 0s 671us/step - loss: 0.0282 - val_loss: 0.3366\n",
      "Epoch 94/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.3336\n",
      "Epoch 95/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.3306\n",
      "Epoch 96/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.3276\n",
      "Epoch 97/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.3247\n",
      "Epoch 98/1200\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.0259 - val_loss: 0.3217\n",
      "Epoch 99/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.3188\n",
      "Epoch 100/1200\n",
      "5/5 [==============================] - 0s 844us/step - loss: 0.0251 - val_loss: 0.3159\n",
      "Epoch 101/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3131\n",
      "Epoch 102/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3102\n",
      "Epoch 103/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.3074\n",
      "Epoch 104/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0235 - val_loss: 0.3046\n",
      "Epoch 105/1200\n",
      "5/5 [==============================] - 0s 472us/step - loss: 0.0232 - val_loss: 0.3019\n",
      "Epoch 106/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.2991\n",
      "Epoch 107/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.2964\n",
      "Epoch 108/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.2937\n",
      "Epoch 109/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.2911\n",
      "Epoch 110/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.2885\n",
      "Epoch 111/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.2859\n",
      "Epoch 112/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.2833\n",
      "Epoch 113/1200\n",
      "5/5 [==============================] - 0s 835us/step - loss: 0.0205 - val_loss: 0.2807\n",
      "Epoch 114/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.2782\n",
      "Epoch 115/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.2758\n",
      "Epoch 116/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.2733\n",
      "Epoch 117/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.2709\n",
      "Epoch 118/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.2685\n",
      "Epoch 119/1200\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0189 - val_loss: 0.2661\n",
      "Epoch 120/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.2638\n",
      "Epoch 121/1200\n",
      "5/5 [==============================] - 0s 874us/step - loss: 0.0185 - val_loss: 0.2615\n",
      "Epoch 122/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.2592\n",
      "Epoch 123/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.2569\n",
      "Epoch 124/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.2547\n",
      "Epoch 125/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.2526\n",
      "Epoch 126/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.2504\n",
      "Epoch 127/1200\n",
      "5/5 [==============================] - 0s 863us/step - loss: 0.0172 - val_loss: 0.2483\n",
      "Epoch 128/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.2462\n",
      "Epoch 129/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2441\n",
      "Epoch 130/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.2421\n",
      "Epoch 131/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.2401\n",
      "Epoch 132/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.2381\n",
      "Epoch 133/1200\n",
      "5/5 [==============================] - 0s 958us/step - loss: 0.0162 - val_loss: 0.2362\n",
      "Epoch 134/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.2343\n",
      "Epoch 135/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.2324\n",
      "Epoch 136/1200\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.0158 - val_loss: 0.2306\n",
      "Epoch 137/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.2288\n",
      "Epoch 138/1200\n",
      "5/5 [==============================] - 0s 826us/step - loss: 0.0156 - val_loss: 0.2270\n",
      "Epoch 139/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2252\n",
      "Epoch 140/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.2235\n",
      "Epoch 141/1200\n",
      "5/5 [==============================] - 0s 624us/step - loss: 0.0152 - val_loss: 0.2218\n",
      "Epoch 142/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.2201\n",
      "Epoch 143/1200\n",
      "5/5 [==============================] - 0s 636us/step - loss: 0.0150 - val_loss: 0.2185\n",
      "Epoch 144/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.2169\n",
      "Epoch 145/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.2153\n",
      "Epoch 146/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.2138\n",
      "Epoch 147/1200\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.0147 - val_loss: 0.2123\n",
      "Epoch 148/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2108\n",
      "Epoch 149/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.2093\n",
      "Epoch 150/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.2079\n",
      "Epoch 151/1200\n",
      "5/5 [==============================] - 0s 503us/step - loss: 0.0143 - val_loss: 0.2065\n",
      "Epoch 152/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2051\n",
      "Epoch 153/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.2037\n",
      "Epoch 154/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.2024\n",
      "Epoch 155/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.2011\n",
      "Epoch 156/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1998\n",
      "Epoch 157/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1986\n",
      "Epoch 158/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1974\n",
      "Epoch 159/1200\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0138 - val_loss: 0.1962\n",
      "Epoch 160/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1950\n",
      "Epoch 161/1200\n",
      "5/5 [==============================] - 0s 717us/step - loss: 0.0137 - val_loss: 0.1938\n",
      "Epoch 162/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1927\n",
      "Epoch 163/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1916\n",
      "Epoch 164/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1895\n",
      "Epoch 166/1200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0135 - val_loss: 0.1884\n",
      "Epoch 167/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1874\n",
      "Epoch 168/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1864\n",
      "Epoch 169/1200\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.0134 - val_loss: 0.1855\n",
      "Epoch 170/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1845\n",
      "Epoch 171/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1836\n",
      "Epoch 172/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1827\n",
      "Epoch 173/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1818\n",
      "Epoch 174/1200\n",
      "5/5 [==============================] - 0s 792us/step - loss: 0.0132 - val_loss: 0.1809\n",
      "Epoch 175/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1800\n",
      "Epoch 176/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1792\n",
      "Epoch 177/1200\n",
      "5/5 [==============================] - 0s 614us/step - loss: 0.0131 - val_loss: 0.1784\n",
      "Epoch 178/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1776\n",
      "Epoch 179/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1768\n",
      "Epoch 180/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1760\n",
      "Epoch 181/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1752\n",
      "Epoch 182/1200\n",
      "5/5 [==============================] - 0s 621us/step - loss: 0.0129 - val_loss: 0.1745\n",
      "Epoch 183/1200\n",
      "5/5 [==============================] - 0s 736us/step - loss: 0.0129 - val_loss: 0.1738\n",
      "Epoch 184/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1730\n",
      "Epoch 185/1200\n",
      "5/5 [==============================] - 0s 565us/step - loss: 0.0128 - val_loss: 0.1723\n",
      "Epoch 186/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1717\n",
      "Epoch 187/1200\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.0128 - val_loss: 0.1710\n",
      "Epoch 188/1200\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.0127 - val_loss: 0.1703\n",
      "Epoch 189/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1697\n",
      "Epoch 190/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1690\n",
      "Epoch 191/1200\n",
      "5/5 [==============================] - 0s 927us/step - loss: 0.0126 - val_loss: 0.1684\n",
      "Epoch 192/1200\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.0126 - val_loss: 0.1678\n",
      "Epoch 193/1200\n",
      "5/5 [==============================] - 0s 588us/step - loss: 0.0126 - val_loss: 0.1671\n",
      "Epoch 194/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1665\n",
      "Epoch 195/1200\n",
      "5/5 [==============================] - 0s 722us/step - loss: 0.0125 - val_loss: 0.1660\n",
      "Epoch 196/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1654\n",
      "Epoch 197/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1648\n",
      "Epoch 198/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1642\n",
      "Epoch 199/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1637\n",
      "Epoch 200/1200\n",
      "5/5 [==============================] - 0s 809us/step - loss: 0.0124 - val_loss: 0.1631\n",
      "Epoch 201/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1626\n",
      "Epoch 202/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1621\n",
      "Epoch 203/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1615\n",
      "Epoch 204/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1610\n",
      "Epoch 205/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1605\n",
      "Epoch 206/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1600\n",
      "Epoch 207/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1595\n",
      "Epoch 208/1200\n",
      "5/5 [==============================] - 0s 744us/step - loss: 0.0121 - val_loss: 0.1590\n",
      "Epoch 209/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1585\n",
      "Epoch 210/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1580\n",
      "Epoch 211/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1575\n",
      "Epoch 212/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1570\n",
      "Epoch 213/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1566\n",
      "Epoch 214/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1561\n",
      "Epoch 215/1200\n",
      "5/5 [==============================] - 0s 904us/step - loss: 0.0119 - val_loss: 0.1556\n",
      "Epoch 216/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1551\n",
      "Epoch 217/1200\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.0119 - val_loss: 0.1547\n",
      "Epoch 218/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1542\n",
      "Epoch 219/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1538\n",
      "Epoch 220/1200\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.0118 - val_loss: 0.1533\n",
      "Epoch 221/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1529\n",
      "Epoch 222/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1524\n",
      "Epoch 223/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1520\n",
      "Epoch 224/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1515\n",
      "Epoch 225/1200\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.0116 - val_loss: 0.1511\n",
      "Epoch 226/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1506\n",
      "Epoch 227/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1502\n",
      "Epoch 228/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1498\n",
      "Epoch 229/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1493\n",
      "Epoch 230/1200\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.0115 - val_loss: 0.1489\n",
      "Epoch 231/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1485\n",
      "Epoch 232/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1480\n",
      "Epoch 233/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1476\n",
      "Epoch 234/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.1472\n",
      "Epoch 235/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1468\n",
      "Epoch 236/1200\n",
      "5/5 [==============================] - 0s 693us/step - loss: 0.0113 - val_loss: 0.1463\n",
      "Epoch 237/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1459\n",
      "Epoch 238/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1455\n",
      "Epoch 239/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1450\n",
      "Epoch 240/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1446\n",
      "Epoch 241/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1442\n",
      "Epoch 242/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1438\n",
      "Epoch 243/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1433\n",
      "Epoch 244/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1429\n",
      "Epoch 245/1200\n",
      "5/5 [==============================] - 0s 937us/step - loss: 0.0111 - val_loss: 0.1425\n",
      "Epoch 246/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 247/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1416\n",
      "Epoch 248/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1412\n",
      "Epoch 249/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1408\n",
      "Epoch 250/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1404\n",
      "Epoch 251/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1399\n",
      "Epoch 252/1200\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.0108 - val_loss: 0.1395\n",
      "Epoch 253/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1391\n",
      "Epoch 254/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1387\n",
      "Epoch 255/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1382\n",
      "Epoch 256/1200\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.0107 - val_loss: 0.1378\n",
      "Epoch 257/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1374\n",
      "Epoch 258/1200\n",
      "5/5 [==============================] - 0s 529us/step - loss: 0.0107 - val_loss: 0.1370\n",
      "Epoch 259/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1365\n",
      "Epoch 260/1200\n",
      "5/5 [==============================] - 0s 564us/step - loss: 0.0106 - val_loss: 0.1361\n",
      "Epoch 261/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1357\n",
      "Epoch 262/1200\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.0105 - val_loss: 0.1353\n",
      "Epoch 263/1200\n",
      "5/5 [==============================] - 0s 712us/step - loss: 0.0105 - val_loss: 0.1348\n",
      "Epoch 264/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1344\n",
      "Epoch 265/1200\n",
      "5/5 [==============================] - 0s 723us/step - loss: 0.0105 - val_loss: 0.1340\n",
      "Epoch 266/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1335\n",
      "Epoch 267/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1331\n",
      "Epoch 268/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1327\n",
      "Epoch 269/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1323\n",
      "Epoch 270/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1318\n",
      "Epoch 271/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1314\n",
      "Epoch 272/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1310\n",
      "Epoch 273/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1305\n",
      "Epoch 274/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1301\n",
      "Epoch 275/1200\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.0102 - val_loss: 0.1297\n",
      "Epoch 276/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1292\n",
      "Epoch 277/1200\n",
      "5/5 [==============================] - 0s 560us/step - loss: 0.0101 - val_loss: 0.1288\n",
      "Epoch 278/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1284\n",
      "Epoch 279/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1279\n",
      "Epoch 280/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1275\n",
      "Epoch 281/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1271\n",
      "Epoch 282/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1266\n",
      "Epoch 283/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1262\n",
      "Epoch 284/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1258\n",
      "Epoch 285/1200\n",
      "5/5 [==============================] - 0s 780us/step - loss: 0.0099 - val_loss: 0.1253\n",
      "Epoch 286/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1249\n",
      "Epoch 287/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.1245\n",
      "Epoch 288/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1240\n",
      "Epoch 289/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1236\n",
      "Epoch 290/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1232\n",
      "Epoch 291/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1227\n",
      "Epoch 292/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1223\n",
      "Epoch 293/1200\n",
      "5/5 [==============================] - 0s 697us/step - loss: 0.0096 - val_loss: 0.1219\n",
      "Epoch 294/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1214\n",
      "Epoch 295/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1210\n",
      "Epoch 296/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1206\n",
      "Epoch 297/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1201\n",
      "Epoch 298/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1197\n",
      "Epoch 299/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1193\n",
      "Epoch 300/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1188\n",
      "Epoch 301/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.1184\n",
      "Epoch 302/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1179\n",
      "Epoch 303/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1175\n",
      "Epoch 304/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1171\n",
      "Epoch 305/1200\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.0092 - val_loss: 0.1166\n",
      "Epoch 306/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1162\n",
      "Epoch 307/1200\n",
      "5/5 [==============================] - 0s 940us/step - loss: 0.0092 - val_loss: 0.1158\n",
      "Epoch 308/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1153\n",
      "Epoch 309/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1149\n",
      "Epoch 310/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1144\n",
      "Epoch 311/1200\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.0091 - val_loss: 0.1140\n",
      "Epoch 312/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1136\n",
      "Epoch 313/1200\n",
      "5/5 [==============================] - 0s 604us/step - loss: 0.0090 - val_loss: 0.1131\n",
      "Epoch 314/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.1127\n",
      "Epoch 315/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1123\n",
      "Epoch 316/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1118\n",
      "Epoch 317/1200\n",
      "5/5 [==============================] - 0s 592us/step - loss: 0.0089 - val_loss: 0.1114\n",
      "Epoch 318/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1109\n",
      "Epoch 319/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1105\n",
      "Epoch 320/1200\n",
      "5/5 [==============================] - 0s 621us/step - loss: 0.0088 - val_loss: 0.1101\n",
      "Epoch 321/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.1096\n",
      "Epoch 322/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1092\n",
      "Epoch 323/1200\n",
      "5/5 [==============================] - 0s 660us/step - loss: 0.0087 - val_loss: 0.1088\n",
      "Epoch 324/1200\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.0087 - val_loss: 0.1083\n",
      "Epoch 325/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1079\n",
      "Epoch 326/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1074\n",
      "Epoch 327/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1070\n",
      "Epoch 328/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1061\n",
      "Epoch 330/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1057\n",
      "Epoch 331/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1052\n",
      "Epoch 332/1200\n",
      "5/5 [==============================] - 0s 721us/step - loss: 0.0084 - val_loss: 0.1048\n",
      "Epoch 333/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1044\n",
      "Epoch 334/1200\n",
      "5/5 [==============================] - 0s 791us/step - loss: 0.0083 - val_loss: 0.1039\n",
      "Epoch 335/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1035\n",
      "Epoch 336/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1031\n",
      "Epoch 337/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1026\n",
      "Epoch 338/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1022\n",
      "Epoch 339/1200\n",
      "5/5 [==============================] - 0s 926us/step - loss: 0.0082 - val_loss: 0.1017\n",
      "Epoch 340/1200\n",
      "5/5 [==============================] - 0s 866us/step - loss: 0.0082 - val_loss: 0.1013\n",
      "Epoch 341/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1009\n",
      "Epoch 342/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1004\n",
      "Epoch 343/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1000\n",
      "Epoch 344/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0996\n",
      "Epoch 345/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0991\n",
      "Epoch 346/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0987\n",
      "Epoch 347/1200\n",
      "5/5 [==============================] - 0s 521us/step - loss: 0.0079 - val_loss: 0.0983\n",
      "Epoch 348/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0978\n",
      "Epoch 349/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0974\n",
      "Epoch 350/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0969\n",
      "Epoch 351/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0965\n",
      "Epoch 352/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0961\n",
      "Epoch 353/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0956\n",
      "Epoch 354/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0952\n",
      "Epoch 355/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0948\n",
      "Epoch 356/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0943\n",
      "Epoch 357/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0939\n",
      "Epoch 358/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0935\n",
      "Epoch 359/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0930\n",
      "Epoch 360/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0926\n",
      "Epoch 361/1200\n",
      "5/5 [==============================] - 0s 643us/step - loss: 0.0075 - val_loss: 0.0922\n",
      "Epoch 362/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0917\n",
      "Epoch 363/1200\n",
      "5/5 [==============================] - 0s 534us/step - loss: 0.0075 - val_loss: 0.0913\n",
      "Epoch 364/1200\n",
      "5/5 [==============================] - 0s 680us/step - loss: 0.0074 - val_loss: 0.0909\n",
      "Epoch 365/1200\n",
      "5/5 [==============================] - 0s 584us/step - loss: 0.0074 - val_loss: 0.0904\n",
      "Epoch 366/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0900\n",
      "Epoch 367/1200\n",
      "5/5 [==============================] - 0s 616us/step - loss: 0.0073 - val_loss: 0.0896\n",
      "Epoch 368/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0891\n",
      "Epoch 369/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0887\n",
      "Epoch 370/1200\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.0072 - val_loss: 0.0883\n",
      "Epoch 371/1200\n",
      "5/5 [==============================] - 0s 550us/step - loss: 0.0072 - val_loss: 0.0878\n",
      "Epoch 372/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0874\n",
      "Epoch 373/1200\n",
      "5/5 [==============================] - 0s 673us/step - loss: 0.0071 - val_loss: 0.0870\n",
      "Epoch 374/1200\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.0071 - val_loss: 0.0865\n",
      "Epoch 375/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0861\n",
      "Epoch 376/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0857\n",
      "Epoch 377/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0852\n",
      "Epoch 378/1200\n",
      "5/5 [==============================] - 0s 956us/step - loss: 0.0070 - val_loss: 0.0848\n",
      "Epoch 379/1200\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.0070 - val_loss: 0.0844\n",
      "Epoch 380/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0839\n",
      "Epoch 381/1200\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0069 - val_loss: 0.0835\n",
      "Epoch 382/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0831\n",
      "Epoch 383/1200\n",
      "5/5 [==============================] - 0s 879us/step - loss: 0.0068 - val_loss: 0.0827\n",
      "Epoch 384/1200\n",
      "5/5 [==============================] - 0s 907us/step - loss: 0.0068 - val_loss: 0.0822\n",
      "Epoch 385/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0818\n",
      "Epoch 386/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0814\n",
      "Epoch 387/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0809\n",
      "Epoch 388/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0805\n",
      "Epoch 389/1200\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.0067 - val_loss: 0.0801\n",
      "Epoch 390/1200\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.0066 - val_loss: 0.0797\n",
      "Epoch 391/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0792\n",
      "Epoch 392/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0788\n",
      "Epoch 393/1200\n",
      "5/5 [==============================] - 0s 698us/step - loss: 0.0065 - val_loss: 0.0784\n",
      "Epoch 394/1200\n",
      "5/5 [==============================] - 0s 722us/step - loss: 0.0065 - val_loss: 0.0780\n",
      "Epoch 395/1200\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0065 - val_loss: 0.0775\n",
      "Epoch 396/1200\n",
      "5/5 [==============================] - 0s 657us/step - loss: 0.0064 - val_loss: 0.0771\n",
      "Epoch 397/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0767\n",
      "Epoch 398/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0763\n",
      "Epoch 399/1200\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.0064 - val_loss: 0.0758\n",
      "Epoch 400/1200\n",
      "5/5 [==============================] - 0s 628us/step - loss: 0.0063 - val_loss: 0.0754\n",
      "Epoch 401/1200\n",
      "5/5 [==============================] - 0s 977us/step - loss: 0.0063 - val_loss: 0.0750\n",
      "Epoch 402/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0746\n",
      "Epoch 403/1200\n",
      "5/5 [==============================] - 0s 736us/step - loss: 0.0062 - val_loss: 0.0742\n",
      "Epoch 404/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0737\n",
      "Epoch 405/1200\n",
      "5/5 [==============================] - 0s 505us/step - loss: 0.0062 - val_loss: 0.0733\n",
      "Epoch 406/1200\n",
      "5/5 [==============================] - 0s 871us/step - loss: 0.0061 - val_loss: 0.0729\n",
      "Epoch 407/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0725\n",
      "Epoch 408/1200\n",
      "5/5 [==============================] - 0s 850us/step - loss: 0.0061 - val_loss: 0.0721\n",
      "Epoch 409/1200\n",
      "5/5 [==============================] - 0s 970us/step - loss: 0.0060 - val_loss: 0.0716\n",
      "Epoch 410/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/1200\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.0060 - val_loss: 0.0708\n",
      "Epoch 412/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0704\n",
      "Epoch 413/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0700\n",
      "Epoch 414/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0696\n",
      "Epoch 415/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0691\n",
      "Epoch 416/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0687\n",
      "Epoch 417/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0683\n",
      "Epoch 418/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0679\n",
      "Epoch 419/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0675\n",
      "Epoch 420/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0671\n",
      "Epoch 421/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0667\n",
      "Epoch 422/1200\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.0057 - val_loss: 0.0663\n",
      "Epoch 423/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0659\n",
      "Epoch 424/1200\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.0056 - val_loss: 0.0654\n",
      "Epoch 425/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0650\n",
      "Epoch 426/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0646\n",
      "Epoch 427/1200\n",
      "5/5 [==============================] - 0s 662us/step - loss: 0.0055 - val_loss: 0.0642\n",
      "Epoch 428/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0638\n",
      "Epoch 429/1200\n",
      "5/5 [==============================] - 0s 569us/step - loss: 0.0054 - val_loss: 0.0634\n",
      "Epoch 430/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0630\n",
      "Epoch 431/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0626\n",
      "Epoch 432/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0622\n",
      "Epoch 433/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0618\n",
      "Epoch 434/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0614\n",
      "Epoch 435/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0610\n",
      "Epoch 436/1200\n",
      "5/5 [==============================] - 0s 656us/step - loss: 0.0052 - val_loss: 0.0606\n",
      "Epoch 437/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0602\n",
      "Epoch 438/1200\n",
      "5/5 [==============================] - 0s 876us/step - loss: 0.0052 - val_loss: 0.0598\n",
      "Epoch 439/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0594\n",
      "Epoch 440/1200\n",
      "5/5 [==============================] - 0s 528us/step - loss: 0.0051 - val_loss: 0.0590\n",
      "Epoch 441/1200\n",
      "5/5 [==============================] - 0s 708us/step - loss: 0.0051 - val_loss: 0.0586\n",
      "Epoch 442/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0582\n",
      "Epoch 443/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0578\n",
      "Epoch 444/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0574\n",
      "Epoch 445/1200\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.0050 - val_loss: 0.0570\n",
      "Epoch 446/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0566\n",
      "Epoch 447/1200\n",
      "5/5 [==============================] - 0s 784us/step - loss: 0.0049 - val_loss: 0.0562\n",
      "Epoch 448/1200\n",
      "5/5 [==============================] - 0s 901us/step - loss: 0.0049 - val_loss: 0.0558\n",
      "Epoch 449/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0554\n",
      "Epoch 450/1200\n",
      "5/5 [==============================] - 0s 871us/step - loss: 0.0048 - val_loss: 0.0551\n",
      "Epoch 451/1200\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.0048 - val_loss: 0.0547\n",
      "Epoch 452/1200\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.0048 - val_loss: 0.0543\n",
      "Epoch 453/1200\n",
      "5/5 [==============================] - 0s 702us/step - loss: 0.0047 - val_loss: 0.0539\n",
      "Epoch 454/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0535\n",
      "Epoch 455/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0531\n",
      "Epoch 456/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0527\n",
      "Epoch 457/1200\n",
      "5/5 [==============================] - 0s 479us/step - loss: 0.0046 - val_loss: 0.0523\n",
      "Epoch 458/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0520\n",
      "Epoch 459/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0516\n",
      "Epoch 460/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0512\n",
      "Epoch 461/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0508\n",
      "Epoch 462/1200\n",
      "5/5 [==============================] - 0s 639us/step - loss: 0.0045 - val_loss: 0.0504\n",
      "Epoch 463/1200\n",
      "5/5 [==============================] - 0s 918us/step - loss: 0.0045 - val_loss: 0.0501\n",
      "Epoch 464/1200\n",
      "5/5 [==============================] - 0s 614us/step - loss: 0.0044 - val_loss: 0.0497\n",
      "Epoch 465/1200\n",
      "5/5 [==============================] - 0s 492us/step - loss: 0.0044 - val_loss: 0.0493\n",
      "Epoch 466/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0489\n",
      "Epoch 467/1200\n",
      "5/5 [==============================] - 0s 795us/step - loss: 0.0044 - val_loss: 0.0486\n",
      "Epoch 468/1200\n",
      "5/5 [==============================] - 0s 911us/step - loss: 0.0043 - val_loss: 0.0482\n",
      "Epoch 469/1200\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.0043 - val_loss: 0.0478\n",
      "Epoch 470/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0474\n",
      "Epoch 471/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0471\n",
      "Epoch 472/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0467\n",
      "Epoch 473/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0463\n",
      "Epoch 474/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0460\n",
      "Epoch 475/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0456\n",
      "Epoch 476/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0452\n",
      "Epoch 477/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0449\n",
      "Epoch 478/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0445\n",
      "Epoch 479/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0441\n",
      "Epoch 480/1200\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0040 - val_loss: 0.0438\n",
      "Epoch 481/1200\n",
      "5/5 [==============================] - 0s 604us/step - loss: 0.0040 - val_loss: 0.0434\n",
      "Epoch 482/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0431\n",
      "Epoch 483/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0427\n",
      "Epoch 484/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0424\n",
      "Epoch 485/1200\n",
      "5/5 [==============================] - 0s 964us/step - loss: 0.0039 - val_loss: 0.0420\n",
      "Epoch 486/1200\n",
      "5/5 [==============================] - 0s 857us/step - loss: 0.0038 - val_loss: 0.0416\n",
      "Epoch 487/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0413\n",
      "Epoch 488/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0409\n",
      "Epoch 489/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0406\n",
      "Epoch 490/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0402\n",
      "Epoch 491/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0399\n",
      "Epoch 492/1200\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0037 - val_loss: 0.0396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0392\n",
      "Epoch 494/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0389\n",
      "Epoch 495/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0385\n",
      "Epoch 496/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0382\n",
      "Epoch 497/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0378\n",
      "Epoch 498/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0375\n",
      "Epoch 499/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0372\n",
      "Epoch 500/1200\n",
      "5/5 [==============================] - 0s 660us/step - loss: 0.0035 - val_loss: 0.0368\n",
      "Epoch 501/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0365\n",
      "Epoch 502/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0362\n",
      "Epoch 503/1200\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0034 - val_loss: 0.0358\n",
      "Epoch 504/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0355\n",
      "Epoch 505/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0352\n",
      "Epoch 506/1200\n",
      "5/5 [==============================] - 0s 513us/step - loss: 0.0033 - val_loss: 0.0348\n",
      "Epoch 507/1200\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.0033 - val_loss: 0.0345\n",
      "Epoch 508/1200\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.0033 - val_loss: 0.0342\n",
      "Epoch 509/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0339\n",
      "Epoch 510/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0335\n",
      "Epoch 511/1200\n",
      "5/5 [==============================] - 0s 936us/step - loss: 0.0032 - val_loss: 0.0332\n",
      "Epoch 512/1200\n",
      "5/5 [==============================] - 0s 913us/step - loss: 0.0032 - val_loss: 0.0329\n",
      "Epoch 513/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0326\n",
      "Epoch 514/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0323\n",
      "Epoch 515/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0319\n",
      "Epoch 516/1200\n",
      "5/5 [==============================] - 0s 555us/step - loss: 0.0031 - val_loss: 0.0316\n",
      "Epoch 517/1200\n",
      "5/5 [==============================] - 0s 843us/step - loss: 0.0030 - val_loss: 0.0313\n",
      "Epoch 518/1200\n",
      "5/5 [==============================] - 0s 709us/step - loss: 0.0030 - val_loss: 0.0310\n",
      "Epoch 519/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0307\n",
      "Epoch 520/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0304\n",
      "Epoch 521/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0301\n",
      "Epoch 522/1200\n",
      "5/5 [==============================] - 0s 792us/step - loss: 0.0029 - val_loss: 0.0298\n",
      "Epoch 523/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0295\n",
      "Epoch 524/1200\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.0029 - val_loss: 0.0292\n",
      "Epoch 525/1200\n",
      "5/5 [==============================] - 0s 959us/step - loss: 0.0028 - val_loss: 0.0289\n",
      "Epoch 526/1200\n",
      "5/5 [==============================] - 0s 734us/step - loss: 0.0028 - val_loss: 0.0286\n",
      "Epoch 527/1200\n",
      "5/5 [==============================] - 0s 790us/step - loss: 0.0028 - val_loss: 0.0283\n",
      "Epoch 528/1200\n",
      "5/5 [==============================] - 0s 825us/step - loss: 0.0028 - val_loss: 0.0280\n",
      "Epoch 529/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0277\n",
      "Epoch 530/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0274\n",
      "Epoch 531/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0271\n",
      "Epoch 532/1200\n",
      "5/5 [==============================] - 0s 768us/step - loss: 0.0027 - val_loss: 0.0268\n",
      "Epoch 533/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0265\n",
      "Epoch 534/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0262\n",
      "Epoch 535/1200\n",
      "5/5 [==============================] - 0s 724us/step - loss: 0.0026 - val_loss: 0.0259\n",
      "Epoch 536/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0256\n",
      "Epoch 537/1200\n",
      "5/5 [==============================] - 0s 500us/step - loss: 0.0026 - val_loss: 0.0254\n",
      "Epoch 538/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0251\n",
      "Epoch 539/1200\n",
      "5/5 [==============================] - 0s 512us/step - loss: 0.0025 - val_loss: 0.0248\n",
      "Epoch 540/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0245\n",
      "Epoch 541/1200\n",
      "5/5 [==============================] - 0s 538us/step - loss: 0.0025 - val_loss: 0.0242\n",
      "Epoch 542/1200\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.0025 - val_loss: 0.0240\n",
      "Epoch 543/1200\n",
      "5/5 [==============================] - 0s 472us/step - loss: 0.0024 - val_loss: 0.0237\n",
      "Epoch 544/1200\n",
      "5/5 [==============================] - 0s 501us/step - loss: 0.0024 - val_loss: 0.0234\n",
      "Epoch 545/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0231\n",
      "Epoch 546/1200\n",
      "5/5 [==============================] - 0s 542us/step - loss: 0.0024 - val_loss: 0.0229\n",
      "Epoch 547/1200\n",
      "5/5 [==============================] - 0s 895us/step - loss: 0.0023 - val_loss: 0.0226\n",
      "Epoch 548/1200\n",
      "5/5 [==============================] - 0s 612us/step - loss: 0.0023 - val_loss: 0.0223\n",
      "Epoch 549/1200\n",
      "5/5 [==============================] - 0s 849us/step - loss: 0.0023 - val_loss: 0.0221\n",
      "Epoch 550/1200\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0023 - val_loss: 0.0218\n",
      "Epoch 551/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0216\n",
      "Epoch 552/1200\n",
      "5/5 [==============================] - 0s 911us/step - loss: 0.0022 - val_loss: 0.0213\n",
      "Epoch 553/1200\n",
      "5/5 [==============================] - 0s 686us/step - loss: 0.0022 - val_loss: 0.0210\n",
      "Epoch 554/1200\n",
      "5/5 [==============================] - 0s 943us/step - loss: 0.0022 - val_loss: 0.0208\n",
      "Epoch 555/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0205\n",
      "Epoch 556/1200\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.0022 - val_loss: 0.0203\n",
      "Epoch 557/1200\n",
      "5/5 [==============================] - 0s 508us/step - loss: 0.0021 - val_loss: 0.0200\n",
      "Epoch 558/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0198\n",
      "Epoch 559/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0195\n",
      "Epoch 560/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0193\n",
      "Epoch 561/1200\n",
      "5/5 [==============================] - 0s 680us/step - loss: 0.0021 - val_loss: 0.0190\n",
      "Epoch 562/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0188\n",
      "Epoch 563/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - val_loss: 0.0186\n",
      "Epoch 564/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0183\n",
      "Epoch 565/1200\n",
      "5/5 [==============================] - 0s 710us/step - loss: 0.0020 - val_loss: 0.0181\n",
      "Epoch 566/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0178\n",
      "Epoch 567/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0176\n",
      "Epoch 568/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0174\n",
      "Epoch 569/1200\n",
      "5/5 [==============================] - 0s 889us/step - loss: 0.0019 - val_loss: 0.0171\n",
      "Epoch 570/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0169\n",
      "Epoch 571/1200\n",
      "5/5 [==============================] - 0s 678us/step - loss: 0.0019 - val_loss: 0.0167\n",
      "Epoch 572/1200\n",
      "5/5 [==============================] - 0s 632us/step - loss: 0.0018 - val_loss: 0.0165\n",
      "Epoch 573/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0162\n",
      "Epoch 574/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - val_loss: 0.0160\n",
      "Epoch 575/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0158\n",
      "Epoch 576/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0156\n",
      "Epoch 577/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0154\n",
      "Epoch 578/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0151\n",
      "Epoch 579/1200\n",
      "5/5 [==============================] - 0s 855us/step - loss: 0.0017 - val_loss: 0.0149\n",
      "Epoch 580/1200\n",
      "5/5 [==============================] - 0s 591us/step - loss: 0.0017 - val_loss: 0.0147\n",
      "Epoch 581/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0145\n",
      "Epoch 582/1200\n",
      "5/5 [==============================] - 0s 514us/step - loss: 0.0017 - val_loss: 0.0143\n",
      "Epoch 583/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0141\n",
      "Epoch 584/1200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0016 - val_loss: 0.0139\n",
      "Epoch 585/1200\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.0016 - val_loss: 0.0137\n",
      "Epoch 586/1200\n",
      "5/5 [==============================] - 0s 646us/step - loss: 0.0016 - val_loss: 0.0135\n",
      "Epoch 587/1200\n",
      "5/5 [==============================] - 0s 809us/step - loss: 0.0016 - val_loss: 0.0133\n",
      "Epoch 588/1200\n",
      "5/5 [==============================] - 0s 494us/step - loss: 0.0016 - val_loss: 0.0131\n",
      "Epoch 589/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0129\n",
      "Epoch 590/1200\n",
      "5/5 [==============================] - 0s 674us/step - loss: 0.0015 - val_loss: 0.0127\n",
      "Epoch 591/1200\n",
      "5/5 [==============================] - 0s 922us/step - loss: 0.0015 - val_loss: 0.0125\n",
      "Epoch 592/1200\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.0015 - val_loss: 0.0123\n",
      "Epoch 593/1200\n",
      "5/5 [==============================] - 0s 651us/step - loss: 0.0015 - val_loss: 0.0121\n",
      "Epoch 594/1200\n",
      "5/5 [==============================] - 0s 899us/step - loss: 0.0015 - val_loss: 0.0119\n",
      "Epoch 595/1200\n",
      "5/5 [==============================] - 0s 511us/step - loss: 0.0014 - val_loss: 0.0118\n",
      "Epoch 596/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0116\n",
      "Epoch 597/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0114\n",
      "Epoch 598/1200\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.0014 - val_loss: 0.0112\n",
      "Epoch 599/1200\n",
      "5/5 [==============================] - 0s 525us/step - loss: 0.0014 - val_loss: 0.0110\n",
      "Epoch 600/1200\n",
      "5/5 [==============================] - 0s 518us/step - loss: 0.0014 - val_loss: 0.0109\n",
      "Epoch 601/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0107\n",
      "Epoch 602/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0105\n",
      "Epoch 603/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 604/1200\n",
      "5/5 [==============================] - 0s 677us/step - loss: 0.0013 - val_loss: 0.0102\n",
      "Epoch 605/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0100\n",
      "Epoch 606/1200\n",
      "5/5 [==============================] - 0s 862us/step - loss: 0.0013 - val_loss: 0.0098\n",
      "Epoch 607/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0097\n",
      "Epoch 608/1200\n",
      "5/5 [==============================] - 0s 888us/step - loss: 0.0012 - val_loss: 0.0095\n",
      "Epoch 609/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 610/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0092\n",
      "Epoch 611/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0090\n",
      "Epoch 612/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0089\n",
      "Epoch 613/1200\n",
      "5/5 [==============================] - 0s 588us/step - loss: 0.0012 - val_loss: 0.0087\n",
      "Epoch 614/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0086\n",
      "Epoch 615/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0084\n",
      "Epoch 616/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0083\n",
      "Epoch 617/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0081\n",
      "Epoch 618/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 619/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0078\n",
      "Epoch 620/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0077\n",
      "Epoch 621/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - val_loss: 0.0075\n",
      "Epoch 622/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0074\n",
      "Epoch 623/1200\n",
      "5/5 [==============================] - 0s 812us/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 624/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0071\n",
      "Epoch 625/1200\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 626/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.9263e-04 - val_loss: 0.0068\n",
      "Epoch 627/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.8001e-04 - val_loss: 0.0067\n",
      "Epoch 628/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 9.6750e-04 - val_loss: 0.0066\n",
      "Epoch 629/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.5511e-04 - val_loss: 0.0065\n",
      "Epoch 630/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.4282e-04 - val_loss: 0.0063\n",
      "Epoch 631/1200\n",
      "5/5 [==============================] - 0s 616us/step - loss: 9.3065e-04 - val_loss: 0.0062\n",
      "Epoch 632/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.1859e-04 - val_loss: 0.0061\n",
      "Epoch 633/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.0664e-04 - val_loss: 0.0060\n",
      "Epoch 634/1200\n",
      "5/5 [==============================] - 0s 748us/step - loss: 8.9480e-04 - val_loss: 0.0058\n",
      "Epoch 635/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.8307e-04 - val_loss: 0.0057\n",
      "Epoch 636/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.7145e-04 - val_loss: 0.0056\n",
      "Epoch 637/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.5994e-04 - val_loss: 0.0055\n",
      "Epoch 638/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.4854e-04 - val_loss: 0.0054\n",
      "Epoch 639/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.3725e-04 - val_loss: 0.0053\n",
      "Epoch 640/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.2607e-04 - val_loss: 0.0051\n",
      "Epoch 641/1200\n",
      "5/5 [==============================] - 0s 859us/step - loss: 8.1499e-04 - val_loss: 0.0050\n",
      "Epoch 642/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.0402e-04 - val_loss: 0.0049\n",
      "Epoch 643/1200\n",
      "5/5 [==============================] - 0s 594us/step - loss: 7.9317e-04 - val_loss: 0.0048\n",
      "Epoch 644/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.8241e-04 - val_loss: 0.0047\n",
      "Epoch 645/1200\n",
      "5/5 [==============================] - 0s 611us/step - loss: 7.7177e-04 - val_loss: 0.0046\n",
      "Epoch 646/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.6123e-04 - val_loss: 0.0045\n",
      "Epoch 647/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.5080e-04 - val_loss: 0.0044\n",
      "Epoch 648/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.4047e-04 - val_loss: 0.0043\n",
      "Epoch 649/1200\n",
      "5/5 [==============================] - 0s 836us/step - loss: 7.3026e-04 - val_loss: 0.0042\n",
      "Epoch 650/1200\n",
      "5/5 [==============================] - 0s 679us/step - loss: 7.2014e-04 - val_loss: 0.0041\n",
      "Epoch 651/1200\n",
      "5/5 [==============================] - 0s 707us/step - loss: 7.1013e-04 - val_loss: 0.0040\n",
      "Epoch 652/1200\n",
      "5/5 [==============================] - 0s 677us/step - loss: 7.0022e-04 - val_loss: 0.0039\n",
      "Epoch 653/1200\n",
      "5/5 [==============================] - 0s 855us/step - loss: 6.9042e-04 - val_loss: 0.0038\n",
      "Epoch 654/1200\n",
      "5/5 [==============================] - 0s 525us/step - loss: 6.8072e-04 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/1200\n",
      "5/5 [==============================] - 0s 566us/step - loss: 6.7112e-04 - val_loss: 0.0037\n",
      "Epoch 656/1200\n",
      "5/5 [==============================] - 0s 803us/step - loss: 6.6162e-04 - val_loss: 0.0036\n",
      "Epoch 657/1200\n",
      "5/5 [==============================] - 0s 489us/step - loss: 6.5222e-04 - val_loss: 0.0035\n",
      "Epoch 658/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.4293e-04 - val_loss: 0.0034\n",
      "Epoch 659/1200\n",
      "5/5 [==============================] - 0s 892us/step - loss: 6.3374e-04 - val_loss: 0.0033\n",
      "Epoch 660/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.2464e-04 - val_loss: 0.0032\n",
      "Epoch 661/1200\n",
      "5/5 [==============================] - 0s 531us/step - loss: 6.1565e-04 - val_loss: 0.0031\n",
      "Epoch 662/1200\n",
      "5/5 [==============================] - 0s 949us/step - loss: 6.0675e-04 - val_loss: 0.0031\n",
      "Epoch 663/1200\n",
      "5/5 [==============================] - 0s 859us/step - loss: 5.9796e-04 - val_loss: 0.0030\n",
      "Epoch 664/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8926e-04 - val_loss: 0.0029\n",
      "Epoch 665/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8066e-04 - val_loss: 0.0028\n",
      "Epoch 666/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7216e-04 - val_loss: 0.0028\n",
      "Epoch 667/1200\n",
      "5/5 [==============================] - 0s 643us/step - loss: 5.6375e-04 - val_loss: 0.0027\n",
      "Epoch 668/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.5544e-04 - val_loss: 0.0026\n",
      "Epoch 669/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.4722e-04 - val_loss: 0.0025\n",
      "Epoch 670/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3910e-04 - val_loss: 0.0025\n",
      "Epoch 671/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.3107e-04 - val_loss: 0.0024\n",
      "Epoch 672/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.2314e-04 - val_loss: 0.0023\n",
      "Epoch 673/1200\n",
      "5/5 [==============================] - 0s 530us/step - loss: 5.1530e-04 - val_loss: 0.0023\n",
      "Epoch 674/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.0755e-04 - val_loss: 0.0022\n",
      "Epoch 675/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.9990e-04 - val_loss: 0.0021\n",
      "Epoch 676/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.9233e-04 - val_loss: 0.0021\n",
      "Epoch 677/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.8486e-04 - val_loss: 0.0020\n",
      "Epoch 678/1200\n",
      "5/5 [==============================] - 0s 995us/step - loss: 4.7748e-04 - val_loss: 0.0020\n",
      "Epoch 679/1200\n",
      "5/5 [==============================] - 0s 736us/step - loss: 4.7018e-04 - val_loss: 0.0019\n",
      "Epoch 680/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.6298e-04 - val_loss: 0.0018\n",
      "Epoch 681/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.5586e-04 - val_loss: 0.0018\n",
      "Epoch 682/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4884e-04 - val_loss: 0.0017\n",
      "Epoch 683/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4190e-04 - val_loss: 0.0017\n",
      "Epoch 684/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.3504e-04 - val_loss: 0.0016\n",
      "Epoch 685/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2827e-04 - val_loss: 0.0016\n",
      "Epoch 686/1200\n",
      "5/5 [==============================] - 0s 810us/step - loss: 4.2159e-04 - val_loss: 0.0015\n",
      "Epoch 687/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.1499e-04 - val_loss: 0.0015\n",
      "Epoch 688/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.0847e-04 - val_loss: 0.0014\n",
      "Epoch 689/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0204e-04 - val_loss: 0.0014\n",
      "Epoch 690/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.9569e-04 - val_loss: 0.0013\n",
      "Epoch 691/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8943e-04 - val_loss: 0.0013\n",
      "Epoch 692/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8324e-04 - val_loss: 0.0012\n",
      "Epoch 693/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.7713e-04 - val_loss: 0.0012\n",
      "Epoch 694/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.7111e-04 - val_loss: 0.0012\n",
      "Epoch 695/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.6517e-04 - val_loss: 0.0011\n",
      "Epoch 696/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5930e-04 - val_loss: 0.0011\n",
      "Epoch 697/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5351e-04 - val_loss: 0.0010\n",
      "Epoch 698/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4780e-04 - val_loss: 0.0010\n",
      "Epoch 699/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.4217e-04 - val_loss: 9.6351e-04\n",
      "Epoch 700/1200\n",
      "5/5 [==============================] - 0s 501us/step - loss: 3.3661e-04 - val_loss: 9.2696e-04\n",
      "Epoch 701/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3113e-04 - val_loss: 8.9136e-04\n",
      "Epoch 702/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2573e-04 - val_loss: 8.5665e-04\n",
      "Epoch 703/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2039e-04 - val_loss: 8.2283e-04\n",
      "Epoch 704/1200\n",
      "5/5 [==============================] - 0s 838us/step - loss: 3.1513e-04 - val_loss: 7.8991e-04\n",
      "Epoch 705/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.0995e-04 - val_loss: 7.5787e-04\n",
      "Epoch 706/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.0483e-04 - val_loss: 7.2670e-04\n",
      "Epoch 707/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9979e-04 - val_loss: 6.9638e-04\n",
      "Epoch 708/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9482e-04 - val_loss: 6.6691e-04\n",
      "Epoch 709/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8992e-04 - val_loss: 6.3828e-04\n",
      "Epoch 710/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8508e-04 - val_loss: 6.1047e-04\n",
      "Epoch 711/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8032e-04 - val_loss: 5.8347e-04\n",
      "Epoch 712/1200\n",
      "5/5 [==============================] - 0s 827us/step - loss: 2.7562e-04 - val_loss: 5.5728e-04\n",
      "Epoch 713/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.7100e-04 - val_loss: 5.3188e-04\n",
      "Epoch 714/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6644e-04 - val_loss: 5.0726e-04\n",
      "Epoch 715/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6194e-04 - val_loss: 4.8342e-04\n",
      "Epoch 716/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5752e-04 - val_loss: 4.6033e-04\n",
      "Epoch 717/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5315e-04 - val_loss: 4.3799e-04\n",
      "Epoch 718/1200\n",
      "5/5 [==============================] - 0s 631us/step - loss: 2.4885e-04 - val_loss: 4.1638e-04\n",
      "Epoch 719/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4462e-04 - val_loss: 3.9550e-04\n",
      "Epoch 720/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4044e-04 - val_loss: 3.7533e-04\n",
      "Epoch 721/1200\n",
      "5/5 [==============================] - 0s 591us/step - loss: 2.3633e-04 - val_loss: 3.5587e-04\n",
      "Epoch 722/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3228e-04 - val_loss: 3.3711e-04\n",
      "Epoch 723/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2830e-04 - val_loss: 3.1903e-04\n",
      "Epoch 724/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2437e-04 - val_loss: 3.0163e-04\n",
      "Epoch 725/1200\n",
      "5/5 [==============================] - 0s 836us/step - loss: 2.2050e-04 - val_loss: 2.8489e-04\n",
      "Epoch 726/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1669e-04 - val_loss: 2.6880e-04\n",
      "Epoch 727/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1294e-04 - val_loss: 2.5336e-04\n",
      "Epoch 728/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0925e-04 - val_loss: 2.3855e-04\n",
      "Epoch 729/1200\n",
      "5/5 [==============================] - 0s 715us/step - loss: 2.0561e-04 - val_loss: 2.2436e-04\n",
      "Epoch 730/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0203e-04 - val_loss: 2.1078e-04\n",
      "Epoch 731/1200\n",
      "5/5 [==============================] - 0s 850us/step - loss: 1.9851e-04 - val_loss: 1.9781e-04\n",
      "Epoch 732/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9504e-04 - val_loss: 1.8543e-04\n",
      "Epoch 733/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9162e-04 - val_loss: 1.7364e-04\n",
      "Epoch 734/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8826e-04 - val_loss: 1.6241e-04\n",
      "Epoch 735/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8496e-04 - val_loss: 1.5175e-04\n",
      "Epoch 736/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8170e-04 - val_loss: 1.4164e-04\n",
      "Epoch 737/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7850e-04 - val_loss: 1.3208e-04\n",
      "Epoch 738/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7535e-04 - val_loss: 1.2305e-04\n",
      "Epoch 739/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7225e-04 - val_loss: 1.1454e-04\n",
      "Epoch 740/1200\n",
      "5/5 [==============================] - 0s 518us/step - loss: 1.6920e-04 - val_loss: 1.0655e-04\n",
      "Epoch 741/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6620e-04 - val_loss: 9.9067e-05\n",
      "Epoch 742/1200\n",
      "5/5 [==============================] - 0s 772us/step - loss: 1.6325e-04 - val_loss: 9.2077e-05\n",
      "Epoch 743/1200\n",
      "5/5 [==============================] - 0s 810us/step - loss: 1.6034e-04 - val_loss: 8.5575e-05\n",
      "Epoch 744/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5749e-04 - val_loss: 7.9550e-05\n",
      "Epoch 745/1200\n",
      "5/5 [==============================] - 0s 548us/step - loss: 1.5468e-04 - val_loss: 7.3994e-05\n",
      "Epoch 746/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5192e-04 - val_loss: 6.8898e-05\n",
      "Epoch 747/1200\n",
      "5/5 [==============================] - 0s 860us/step - loss: 1.4920e-04 - val_loss: 6.4252e-05\n",
      "Epoch 748/1200\n",
      "5/5 [==============================] - 0s 849us/step - loss: 1.4653e-04 - val_loss: 6.0049e-05\n",
      "Epoch 749/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4391e-04 - val_loss: 5.6278e-05\n",
      "Epoch 750/1200\n",
      "5/5 [==============================] - 0s 824us/step - loss: 1.4132e-04 - val_loss: 5.2932e-05\n",
      "Epoch 751/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3879e-04 - val_loss: 5.0002e-05\n",
      "Epoch 752/1200\n",
      "5/5 [==============================] - 0s 487us/step - loss: 1.3629e-04 - val_loss: 4.7478e-05\n",
      "Epoch 753/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3384e-04 - val_loss: 4.5353e-05\n",
      "Epoch 754/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3143e-04 - val_loss: 4.3619e-05\n",
      "Epoch 755/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2906e-04 - val_loss: 4.2266e-05\n",
      "Epoch 756/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2673e-04 - val_loss: 4.1287e-05\n",
      "Epoch 757/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2444e-04 - val_loss: 4.0674e-05\n",
      "Epoch 758/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2219e-04 - val_loss: 4.0418e-05\n",
      "Epoch 759/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1999e-04 - val_loss: 4.0513e-05\n",
      "Epoch 760/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1781e-04 - val_loss: 4.0948e-05\n",
      "Epoch 761/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1568e-04 - val_loss: 4.1717e-05\n",
      "Epoch 762/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1359e-04 - val_loss: 4.2813e-05\n",
      "Epoch 763/1200\n",
      "5/5 [==============================] - 0s 847us/step - loss: 1.1153e-04 - val_loss: 4.4227e-05\n",
      "Epoch 764/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0951e-04 - val_loss: 4.5953e-05\n",
      "Epoch 765/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0752e-04 - val_loss: 4.7981e-05\n",
      "Epoch 766/1200\n",
      "5/5 [==============================] - 0s 915us/step - loss: 1.0557e-04 - val_loss: 5.0306e-05\n",
      "Epoch 767/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0366e-04 - val_loss: 5.2919e-05\n",
      "Epoch 768/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0178e-04 - val_loss: 5.5814e-05\n",
      "Epoch 769/1200\n",
      "5/5 [==============================] - 0s 907us/step - loss: 9.9929e-05 - val_loss: 5.8984e-05\n",
      "Epoch 770/1200\n",
      "5/5 [==============================] - 0s 672us/step - loss: 9.8115e-05 - val_loss: 6.2421e-05\n",
      "Epoch 771/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.6334e-05 - val_loss: 6.6120e-05\n",
      "Epoch 772/1200\n",
      "5/5 [==============================] - 0s 524us/step - loss: 9.4586e-05 - val_loss: 7.0072e-05\n",
      "Epoch 773/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.2870e-05 - val_loss: 7.4269e-05\n",
      "Epoch 774/1200\n",
      "5/5 [==============================] - 0s 537us/step - loss: 9.1186e-05 - val_loss: 7.8709e-05\n",
      "Epoch 775/1200\n",
      "5/5 [==============================] - 0s 525us/step - loss: 8.9532e-05 - val_loss: 8.3383e-05\n",
      "Epoch 776/1200\n",
      "5/5 [==============================] - 0s 565us/step - loss: 8.7909e-05 - val_loss: 8.8284e-05\n",
      "Epoch 777/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.6316e-05 - val_loss: 9.3405e-05\n",
      "Epoch 778/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.4752e-05 - val_loss: 9.8742e-05\n",
      "Epoch 779/1200\n",
      "5/5 [==============================] - 0s 741us/step - loss: 8.3218e-05 - val_loss: 1.0429e-04\n",
      "Epoch 780/1200\n",
      "5/5 [==============================] - 0s 856us/step - loss: 8.1712e-05 - val_loss: 1.1003e-04\n",
      "Epoch 781/1200\n",
      "5/5 [==============================] - 0s 586us/step - loss: 8.0235e-05 - val_loss: 1.1598e-04\n",
      "Epoch 782/1200\n",
      "5/5 [==============================] - 0s 558us/step - loss: 7.8785e-05 - val_loss: 1.2211e-04\n",
      "Epoch 783/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7363e-05 - val_loss: 1.2843e-04\n",
      "Epoch 784/1200\n",
      "5/5 [==============================] - 0s 617us/step - loss: 7.5967e-05 - val_loss: 1.3493e-04\n",
      "Epoch 785/1200\n",
      "5/5 [==============================] - 0s 637us/step - loss: 7.4599e-05 - val_loss: 1.4160e-04\n",
      "Epoch 786/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.3256e-05 - val_loss: 1.4844e-04\n",
      "Epoch 787/1200\n",
      "5/5 [==============================] - 0s 988us/step - loss: 7.1939e-05 - val_loss: 1.5543e-04\n",
      "Epoch 788/1200\n",
      "5/5 [==============================] - 0s 980us/step - loss: 7.0647e-05 - val_loss: 1.6259e-04\n",
      "Epoch 789/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.9381e-05 - val_loss: 1.6990e-04\n",
      "Epoch 790/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.8138e-05 - val_loss: 1.7735e-04\n",
      "Epoch 791/1200\n",
      "5/5 [==============================] - 0s 933us/step - loss: 6.6920e-05 - val_loss: 1.8494e-04\n",
      "Epoch 792/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.5725e-05 - val_loss: 1.9267e-04\n",
      "Epoch 793/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.4554e-05 - val_loss: 2.0053e-04\n",
      "Epoch 794/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.3405e-05 - val_loss: 2.0851e-04\n",
      "Epoch 795/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2280e-05 - val_loss: 2.1661e-04\n",
      "Epoch 796/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.1176e-05 - val_loss: 2.2483e-04\n",
      "Epoch 797/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.0093e-05 - val_loss: 2.3317e-04\n",
      "Epoch 798/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.9033e-05 - val_loss: 2.4161e-04\n",
      "Epoch 799/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7993e-05 - val_loss: 2.5015e-04\n",
      "Epoch 800/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6974e-05 - val_loss: 2.5878e-04\n",
      "Epoch 801/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.5976e-05 - val_loss: 2.6751e-04\n",
      "Epoch 802/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.4997e-05 - val_loss: 2.7633e-04\n",
      "Epoch 803/1200\n",
      "5/5 [==============================] - 0s 971us/step - loss: 5.4038e-05 - val_loss: 2.8523e-04\n",
      "Epoch 804/1200\n",
      "5/5 [==============================] - 0s 874us/step - loss: 5.3099e-05 - val_loss: 2.9422e-04\n",
      "Epoch 805/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.2178e-05 - val_loss: 3.0328e-04\n",
      "Epoch 806/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.1276e-05 - val_loss: 3.1242e-04\n",
      "Epoch 807/1200\n",
      "5/5 [==============================] - 0s 963us/step - loss: 5.0392e-05 - val_loss: 3.2162e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 808/1200\n",
      "5/5 [==============================] - 0s 537us/step - loss: 4.9526e-05 - val_loss: 3.3089e-04\n",
      "Epoch 809/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8677e-05 - val_loss: 3.4022e-04\n",
      "Epoch 810/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7847e-05 - val_loss: 3.4960e-04\n",
      "Epoch 811/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.7033e-05 - val_loss: 3.5904e-04\n",
      "Epoch 812/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6235e-05 - val_loss: 3.6854e-04\n",
      "Epoch 813/1200\n",
      "5/5 [==============================] - 0s 728us/step - loss: 4.5455e-05 - val_loss: 3.7807e-04\n",
      "Epoch 814/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4690e-05 - val_loss: 3.8765e-04\n",
      "Epoch 815/1200\n",
      "5/5 [==============================] - 0s 508us/step - loss: 4.3941e-05 - val_loss: 3.9727e-04\n",
      "Epoch 816/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.3208e-05 - val_loss: 4.0693e-04\n",
      "Epoch 817/1200\n",
      "5/5 [==============================] - 0s 514us/step - loss: 4.2490e-05 - val_loss: 4.1662e-04\n",
      "Epoch 818/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.1787e-05 - val_loss: 4.2635e-04\n",
      "Epoch 819/1200\n",
      "5/5 [==============================] - 0s 864us/step - loss: 4.1099e-05 - val_loss: 4.3609e-04\n",
      "Epoch 820/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0425e-05 - val_loss: 4.4587e-04\n",
      "Epoch 821/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9766e-05 - val_loss: 4.5566e-04\n",
      "Epoch 822/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9120e-05 - val_loss: 4.6548e-04\n",
      "Epoch 823/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8488e-05 - val_loss: 4.7531e-04\n",
      "Epoch 824/1200\n",
      "5/5 [==============================] - 0s 605us/step - loss: 3.7870e-05 - val_loss: 4.8515e-04\n",
      "Epoch 825/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.7264e-05 - val_loss: 4.9500e-04\n",
      "Epoch 826/1200\n",
      "5/5 [==============================] - 0s 876us/step - loss: 3.6672e-05 - val_loss: 5.0487e-04\n",
      "Epoch 827/1200\n",
      "5/5 [==============================] - 0s 506us/step - loss: 3.6092e-05 - val_loss: 5.1473e-04\n",
      "Epoch 828/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5524e-05 - val_loss: 5.2460e-04\n",
      "Epoch 829/1200\n",
      "5/5 [==============================] - 0s 564us/step - loss: 3.4969e-05 - val_loss: 5.3447e-04\n",
      "Epoch 830/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.4426e-05 - val_loss: 5.4434e-04\n",
      "Epoch 831/1200\n",
      "5/5 [==============================] - 0s 605us/step - loss: 3.3894e-05 - val_loss: 5.5421e-04\n",
      "Epoch 832/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.3374e-05 - val_loss: 5.6407e-04\n",
      "Epoch 833/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2865e-05 - val_loss: 5.7392e-04\n",
      "Epoch 834/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2368e-05 - val_loss: 5.8375e-04\n",
      "Epoch 835/1200\n",
      "5/5 [==============================] - 0s 536us/step - loss: 3.1880e-05 - val_loss: 5.9358e-04\n",
      "Epoch 836/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1404e-05 - val_loss: 6.0339e-04\n",
      "Epoch 837/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0938e-05 - val_loss: 6.1319e-04\n",
      "Epoch 838/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.0483e-05 - val_loss: 6.2296e-04\n",
      "Epoch 839/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0037e-05 - val_loss: 6.3272e-04\n",
      "Epoch 840/1200\n",
      "5/5 [==============================] - 0s 697us/step - loss: 2.9602e-05 - val_loss: 6.4245e-04\n",
      "Epoch 841/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9175e-05 - val_loss: 6.5216e-04\n",
      "Epoch 842/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.8759e-05 - val_loss: 6.6185e-04\n",
      "Epoch 843/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8351e-05 - val_loss: 6.7150e-04\n",
      "Epoch 844/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.7953e-05 - val_loss: 6.8113e-04\n",
      "Epoch 845/1200\n",
      "5/5 [==============================] - 0s 992us/step - loss: 2.7563e-05 - val_loss: 6.9073e-04\n",
      "Epoch 846/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7182e-05 - val_loss: 7.0029e-04\n",
      "Epoch 847/1200\n",
      "5/5 [==============================] - 0s 573us/step - loss: 2.6810e-05 - val_loss: 7.0982e-04\n",
      "Epoch 848/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6446e-05 - val_loss: 7.1932e-04\n",
      "Epoch 849/1200\n",
      "5/5 [==============================] - 0s 574us/step - loss: 2.6090e-05 - val_loss: 7.2878e-04\n",
      "Epoch 850/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5742e-05 - val_loss: 7.3820e-04\n",
      "Epoch 851/1200\n",
      "5/5 [==============================] - 0s 596us/step - loss: 2.5402e-05 - val_loss: 7.4759e-04\n",
      "Epoch 852/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5069e-05 - val_loss: 7.5693e-04\n",
      "Epoch 853/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4745e-05 - val_loss: 7.6624e-04\n",
      "Epoch 854/1200\n",
      "5/5 [==============================] - 0s 537us/step - loss: 2.4427e-05 - val_loss: 7.7550e-04\n",
      "Epoch 855/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4117e-05 - val_loss: 7.8471e-04\n",
      "Epoch 856/1200\n",
      "5/5 [==============================] - 0s 637us/step - loss: 2.3814e-05 - val_loss: 7.9389e-04\n",
      "Epoch 857/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3518e-05 - val_loss: 8.0301e-04\n",
      "Epoch 858/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3228e-05 - val_loss: 8.1209e-04\n",
      "Epoch 859/1200\n",
      "5/5 [==============================] - 0s 514us/step - loss: 2.2945e-05 - val_loss: 8.2113e-04\n",
      "Epoch 860/1200\n",
      "5/5 [==============================] - 0s 913us/step - loss: 2.2669e-05 - val_loss: 8.3011e-04\n",
      "Epoch 861/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2399e-05 - val_loss: 8.3905e-04\n",
      "Epoch 862/1200\n",
      "5/5 [==============================] - 0s 529us/step - loss: 2.2135e-05 - val_loss: 8.4793e-04\n",
      "Epoch 863/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.1878e-05 - val_loss: 8.5676e-04\n",
      "Epoch 864/1200\n",
      "5/5 [==============================] - 0s 509us/step - loss: 2.1626e-05 - val_loss: 8.6555e-04\n",
      "Epoch 865/1200\n",
      "5/5 [==============================] - 0s 536us/step - loss: 2.1380e-05 - val_loss: 8.7428e-04\n",
      "Epoch 866/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1140e-05 - val_loss: 8.8296e-04\n",
      "Epoch 867/1200\n",
      "5/5 [==============================] - 0s 507us/step - loss: 2.0905e-05 - val_loss: 8.9158e-04\n",
      "Epoch 868/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0676e-05 - val_loss: 9.0015e-04\n",
      "Epoch 869/1200\n",
      "5/5 [==============================] - 0s 544us/step - loss: 2.0452e-05 - val_loss: 9.0866e-04\n",
      "Epoch 870/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0234e-05 - val_loss: 9.1712e-04\n",
      "Epoch 871/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0020e-05 - val_loss: 9.2552e-04\n",
      "Epoch 872/1200\n",
      "5/5 [==============================] - 0s 565us/step - loss: 1.9812e-05 - val_loss: 9.3386e-04\n",
      "Epoch 873/1200\n",
      "5/5 [==============================] - 0s 900us/step - loss: 1.9609e-05 - val_loss: 9.4214e-04\n",
      "Epoch 874/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9410e-05 - val_loss: 9.5037e-04\n",
      "Epoch 875/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9216e-05 - val_loss: 9.5854e-04\n",
      "Epoch 876/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.9026e-05 - val_loss: 9.6665e-04\n",
      "Epoch 877/1200\n",
      "5/5 [==============================] - 0s 667us/step - loss: 1.8842e-05 - val_loss: 9.7470e-04\n",
      "Epoch 878/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8661e-05 - val_loss: 9.8270e-04\n",
      "Epoch 879/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8485e-05 - val_loss: 9.9063e-04\n",
      "Epoch 880/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8313e-05 - val_loss: 9.9850e-04\n",
      "Epoch 881/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8145e-05 - val_loss: 0.0010\n",
      "Epoch 882/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7981e-05 - val_loss: 0.0010\n",
      "Epoch 883/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7821e-05 - val_loss: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 884/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7664e-05 - val_loss: 0.0010\n",
      "Epoch 885/1200\n",
      "5/5 [==============================] - 0s 764us/step - loss: 1.7512e-05 - val_loss: 0.0010\n",
      "Epoch 886/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7363e-05 - val_loss: 0.0010\n",
      "Epoch 887/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7218e-05 - val_loss: 0.0011\n",
      "Epoch 888/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7076e-05 - val_loss: 0.0011\n",
      "Epoch 889/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6938e-05 - val_loss: 0.0011\n",
      "Epoch 890/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6803e-05 - val_loss: 0.0011\n",
      "Epoch 891/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6671e-05 - val_loss: 0.0011\n",
      "Epoch 892/1200\n",
      "5/5 [==============================] - 0s 613us/step - loss: 1.6543e-05 - val_loss: 0.0011\n",
      "Epoch 893/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6418e-05 - val_loss: 0.0011\n",
      "Epoch 894/1200\n",
      "5/5 [==============================] - 0s 891us/step - loss: 1.6295e-05 - val_loss: 0.0011\n",
      "Epoch 895/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6176e-05 - val_loss: 0.0011\n",
      "Epoch 896/1200\n",
      "5/5 [==============================] - 0s 544us/step - loss: 1.6060e-05 - val_loss: 0.0011\n",
      "Epoch 897/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5946e-05 - val_loss: 0.0011\n",
      "Epoch 898/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5835e-05 - val_loss: 0.0011\n",
      "Epoch 899/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5727e-05 - val_loss: 0.0011\n",
      "Epoch 900/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5622e-05 - val_loss: 0.0011\n",
      "Epoch 901/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5519e-05 - val_loss: 0.0011\n",
      "Epoch 902/1200\n",
      "5/5 [==============================] - 0s 757us/step - loss: 1.5419e-05 - val_loss: 0.0012\n",
      "Epoch 903/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5321e-05 - val_loss: 0.0012\n",
      "Epoch 904/1200\n",
      "5/5 [==============================] - 0s 909us/step - loss: 1.5225e-05 - val_loss: 0.0012\n",
      "Epoch 905/1200\n",
      "5/5 [==============================] - 0s 529us/step - loss: 1.5132e-05 - val_loss: 0.0012\n",
      "Epoch 906/1200\n",
      "5/5 [==============================] - 0s 993us/step - loss: 1.5041e-05 - val_loss: 0.0012\n",
      "Epoch 907/1200\n",
      "5/5 [==============================] - 0s 547us/step - loss: 1.4953e-05 - val_loss: 0.0012\n",
      "Epoch 908/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4866e-05 - val_loss: 0.0012\n",
      "Epoch 909/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4782e-05 - val_loss: 0.0012\n",
      "Epoch 910/1200\n",
      "5/5 [==============================] - 0s 525us/step - loss: 1.4700e-05 - val_loss: 0.0012\n",
      "Epoch 911/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4620e-05 - val_loss: 0.0012\n",
      "Epoch 912/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4542e-05 - val_loss: 0.0012\n",
      "Epoch 913/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4466e-05 - val_loss: 0.0012\n",
      "Epoch 914/1200\n",
      "5/5 [==============================] - 0s 759us/step - loss: 1.4392e-05 - val_loss: 0.0012\n",
      "Epoch 915/1200\n",
      "5/5 [==============================] - 0s 501us/step - loss: 1.4319e-05 - val_loss: 0.0012\n",
      "Epoch 916/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4249e-05 - val_loss: 0.0012\n",
      "Epoch 917/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4180e-05 - val_loss: 0.0012\n",
      "Epoch 918/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4113e-05 - val_loss: 0.0013\n",
      "Epoch 919/1200\n",
      "5/5 [==============================] - 0s 553us/step - loss: 1.4047e-05 - val_loss: 0.0013\n",
      "Epoch 920/1200\n",
      "5/5 [==============================] - 0s 532us/step - loss: 1.3984e-05 - val_loss: 0.0013\n",
      "Epoch 921/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3921e-05 - val_loss: 0.0013\n",
      "Epoch 922/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3861e-05 - val_loss: 0.0013\n",
      "Epoch 923/1200\n",
      "5/5 [==============================] - 0s 860us/step - loss: 1.3802e-05 - val_loss: 0.0013\n",
      "Epoch 924/1200\n",
      "5/5 [==============================] - 0s 967us/step - loss: 1.3744e-05 - val_loss: 0.0013\n",
      "Epoch 925/1200\n",
      "5/5 [==============================] - 0s 964us/step - loss: 1.3688e-05 - val_loss: 0.0013\n",
      "Epoch 926/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3633e-05 - val_loss: 0.0013\n",
      "Epoch 927/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.3580e-05 - val_loss: 0.0013\n",
      "Epoch 928/1200\n",
      "5/5 [==============================] - 0s 897us/step - loss: 1.3528e-05 - val_loss: 0.0013\n",
      "Epoch 929/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3477e-05 - val_loss: 0.0013\n",
      "Epoch 930/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3428e-05 - val_loss: 0.0013\n",
      "Epoch 931/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3379e-05 - val_loss: 0.0013\n",
      "Epoch 932/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3332e-05 - val_loss: 0.0013\n",
      "Epoch 933/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3287e-05 - val_loss: 0.0013\n",
      "Epoch 934/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3242e-05 - val_loss: 0.0013\n",
      "Epoch 935/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3199e-05 - val_loss: 0.0013\n",
      "Epoch 936/1200\n",
      "5/5 [==============================] - 0s 688us/step - loss: 1.3156e-05 - val_loss: 0.0013\n",
      "Epoch 937/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3115e-05 - val_loss: 0.0013\n",
      "Epoch 938/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3075e-05 - val_loss: 0.0014\n",
      "Epoch 939/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3035e-05 - val_loss: 0.0014\n",
      "Epoch 940/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2997e-05 - val_loss: 0.0014\n",
      "Epoch 941/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2960e-05 - val_loss: 0.0014\n",
      "Epoch 942/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2924e-05 - val_loss: 0.0014\n",
      "Epoch 943/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2888e-05 - val_loss: 0.0014\n",
      "Epoch 944/1200\n",
      "5/5 [==============================] - 0s 971us/step - loss: 1.2854e-05 - val_loss: 0.0014\n",
      "Epoch 945/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2820e-05 - val_loss: 0.0014\n",
      "Epoch 946/1200\n",
      "5/5 [==============================] - 0s 931us/step - loss: 1.2787e-05 - val_loss: 0.0014\n",
      "Epoch 947/1200\n",
      "5/5 [==============================] - 0s 959us/step - loss: 1.2755e-05 - val_loss: 0.0014\n",
      "Epoch 948/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2724e-05 - val_loss: 0.0014\n",
      "Epoch 949/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2694e-05 - val_loss: 0.0014\n",
      "Epoch 950/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2664e-05 - val_loss: 0.0014\n",
      "Epoch 951/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2635e-05 - val_loss: 0.0014\n",
      "Epoch 952/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2607e-05 - val_loss: 0.0014\n",
      "Epoch 953/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2580e-05 - val_loss: 0.0014\n",
      "Epoch 954/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2553e-05 - val_loss: 0.0014\n",
      "Epoch 955/1200\n",
      "5/5 [==============================] - 0s 916us/step - loss: 1.2527e-05 - val_loss: 0.0014\n",
      "Epoch 956/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2502e-05 - val_loss: 0.0014\n",
      "Epoch 957/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2477e-05 - val_loss: 0.0014\n",
      "Epoch 958/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2453e-05 - val_loss: 0.0014\n",
      "Epoch 959/1200\n",
      "5/5 [==============================] - 0s 760us/step - loss: 1.2430e-05 - val_loss: 0.0014\n",
      "Epoch 960/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2407e-05 - val_loss: 0.0014\n",
      "Epoch 961/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2384e-05 - val_loss: 0.0014\n",
      "Epoch 962/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2363e-05 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1200\n",
      "5/5 [==============================] - 0s 926us/step - loss: 1.2342e-05 - val_loss: 0.0014\n",
      "Epoch 964/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2321e-05 - val_loss: 0.0014\n",
      "Epoch 965/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2301e-05 - val_loss: 0.0015\n",
      "Epoch 966/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2281e-05 - val_loss: 0.0015\n",
      "Epoch 967/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2262e-05 - val_loss: 0.0015\n",
      "Epoch 968/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2243e-05 - val_loss: 0.0015\n",
      "Epoch 969/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2225e-05 - val_loss: 0.0015\n",
      "Epoch 970/1200\n",
      "5/5 [==============================] - 0s 538us/step - loss: 1.2207e-05 - val_loss: 0.0015\n",
      "Epoch 971/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2190e-05 - val_loss: 0.0015\n",
      "Epoch 972/1200\n",
      "5/5 [==============================] - 0s 692us/step - loss: 1.2173e-05 - val_loss: 0.0015\n",
      "Epoch 973/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2157e-05 - val_loss: 0.0015\n",
      "Epoch 974/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2141e-05 - val_loss: 0.0015\n",
      "Epoch 975/1200\n",
      "5/5 [==============================] - 0s 571us/step - loss: 1.2125e-05 - val_loss: 0.0015\n",
      "Epoch 976/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2110e-05 - val_loss: 0.0015\n",
      "Epoch 977/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2095e-05 - val_loss: 0.0015\n",
      "Epoch 978/1200\n",
      "5/5 [==============================] - 0s 498us/step - loss: 1.2081e-05 - val_loss: 0.0015\n",
      "Epoch 979/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2066e-05 - val_loss: 0.0015\n",
      "Epoch 980/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2053e-05 - val_loss: 0.0015\n",
      "Epoch 981/1200\n",
      "5/5 [==============================] - 0s 854us/step - loss: 1.2039e-05 - val_loss: 0.0015\n",
      "Epoch 982/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.2026e-05 - val_loss: 0.0015\n",
      "Epoch 983/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2013e-05 - val_loss: 0.0015\n",
      "Epoch 984/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2001e-05 - val_loss: 0.0015\n",
      "Epoch 985/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1989e-05 - val_loss: 0.0015\n",
      "Epoch 986/1200\n",
      "5/5 [==============================] - 0s 599us/step - loss: 1.1977e-05 - val_loss: 0.0015\n",
      "Epoch 987/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1965e-05 - val_loss: 0.0015\n",
      "Epoch 988/1200\n",
      "5/5 [==============================] - 0s 927us/step - loss: 1.1954e-05 - val_loss: 0.0015\n",
      "Epoch 989/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1943e-05 - val_loss: 0.0015\n",
      "Epoch 990/1200\n",
      "5/5 [==============================] - 0s 756us/step - loss: 1.1932e-05 - val_loss: 0.0015\n",
      "Epoch 991/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1921e-05 - val_loss: 0.0015\n",
      "Epoch 992/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1911e-05 - val_loss: 0.0015\n",
      "Epoch 993/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1901e-05 - val_loss: 0.0015\n",
      "Epoch 994/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1891e-05 - val_loss: 0.0015\n",
      "Epoch 995/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1882e-05 - val_loss: 0.0015\n",
      "Epoch 996/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1872e-05 - val_loss: 0.0015\n",
      "Epoch 997/1200\n",
      "5/5 [==============================] - 0s 935us/step - loss: 1.1863e-05 - val_loss: 0.0015\n",
      "Epoch 998/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1854e-05 - val_loss: 0.0015\n",
      "Epoch 999/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1846e-05 - val_loss: 0.0015\n",
      "Epoch 1000/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1837e-05 - val_loss: 0.0015\n",
      "Epoch 1001/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1829e-05 - val_loss: 0.0015\n",
      "Epoch 1002/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1821e-05 - val_loss: 0.0015\n",
      "Epoch 1003/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1813e-05 - val_loss: 0.0015\n",
      "Epoch 1004/1200\n",
      "5/5 [==============================] - 0s 730us/step - loss: 1.1805e-05 - val_loss: 0.0015\n",
      "Epoch 1005/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1797e-05 - val_loss: 0.0015\n",
      "Epoch 1006/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1790e-05 - val_loss: 0.0015\n",
      "Epoch 1007/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1783e-05 - val_loss: 0.0015\n",
      "Epoch 1008/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1775e-05 - val_loss: 0.0015\n",
      "Epoch 1009/1200\n",
      "5/5 [==============================] - 0s 839us/step - loss: 1.1768e-05 - val_loss: 0.0016\n",
      "Epoch 1010/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1762e-05 - val_loss: 0.0016\n",
      "Epoch 1011/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1755e-05 - val_loss: 0.0016\n",
      "Epoch 1012/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1749e-05 - val_loss: 0.0016\n",
      "Epoch 1013/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1742e-05 - val_loss: 0.0016\n",
      "Epoch 1014/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1736e-05 - val_loss: 0.0016\n",
      "Epoch 1015/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1730e-05 - val_loss: 0.0016\n",
      "Epoch 1016/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1724e-05 - val_loss: 0.0016\n",
      "Epoch 1017/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1718e-05 - val_loss: 0.0016\n",
      "Epoch 1018/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1712e-05 - val_loss: 0.0016\n",
      "Epoch 1019/1200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 1.1707e-05 - val_loss: 0.0016\n",
      "Epoch 1020/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1701e-05 - val_loss: 0.0016\n",
      "Epoch 1021/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1696e-05 - val_loss: 0.0016\n",
      "Epoch 1022/1200\n",
      "5/5 [==============================] - 0s 948us/step - loss: 1.1691e-05 - val_loss: 0.0016\n",
      "Epoch 1023/1200\n",
      "5/5 [==============================] - 0s 657us/step - loss: 1.1685e-05 - val_loss: 0.0016\n",
      "Epoch 1024/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1680e-05 - val_loss: 0.0016\n",
      "Epoch 1025/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1675e-05 - val_loss: 0.0016\n",
      "Epoch 1026/1200\n",
      "5/5 [==============================] - 0s 842us/step - loss: 1.1671e-05 - val_loss: 0.0016\n",
      "Epoch 1027/1200\n",
      "5/5 [==============================] - 0s 513us/step - loss: 1.1666e-05 - val_loss: 0.0016\n",
      "Epoch 1028/1200\n",
      "5/5 [==============================] - 0s 539us/step - loss: 1.1661e-05 - val_loss: 0.0016\n",
      "Epoch 1029/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1656e-05 - val_loss: 0.0016\n",
      "Epoch 1030/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1652e-05 - val_loss: 0.0016\n",
      "Epoch 1031/1200\n",
      "5/5 [==============================] - 0s 498us/step - loss: 1.1648e-05 - val_loss: 0.0016\n",
      "Epoch 1032/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1643e-05 - val_loss: 0.0016\n",
      "Epoch 1033/1200\n",
      "5/5 [==============================] - 0s 808us/step - loss: 1.1639e-05 - val_loss: 0.0016\n",
      "Epoch 1034/1200\n",
      "5/5 [==============================] - 0s 779us/step - loss: 1.1635e-05 - val_loss: 0.0016\n",
      "Epoch 1035/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1630e-05 - val_loss: 0.0016\n",
      "Epoch 1036/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1626e-05 - val_loss: 0.0016\n",
      "Epoch 1037/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1622e-05 - val_loss: 0.0016\n",
      "Epoch 1038/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1619e-05 - val_loss: 0.0016\n",
      "Epoch 1039/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1615e-05 - val_loss: 0.0016\n",
      "Epoch 1040/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1611e-05 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1041/1200\n",
      "5/5 [==============================] - 0s 957us/step - loss: 1.1607e-05 - val_loss: 0.0016\n",
      "Epoch 1042/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1603e-05 - val_loss: 0.0016\n",
      "Epoch 1043/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1600e-05 - val_loss: 0.0016\n",
      "Epoch 1044/1200\n",
      "5/5 [==============================] - 0s 932us/step - loss: 1.1596e-05 - val_loss: 0.0016\n",
      "Epoch 1045/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1593e-05 - val_loss: 0.0016\n",
      "Epoch 1046/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1589e-05 - val_loss: 0.0016\n",
      "Epoch 1047/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1586e-05 - val_loss: 0.0016\n",
      "Epoch 1048/1200\n",
      "5/5 [==============================] - 0s 679us/step - loss: 1.1583e-05 - val_loss: 0.0016\n",
      "Epoch 1049/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1579e-05 - val_loss: 0.0016\n",
      "Epoch 1050/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1576e-05 - val_loss: 0.0016\n",
      "Epoch 1051/1200\n",
      "5/5 [==============================] - 0s 562us/step - loss: 1.1573e-05 - val_loss: 0.0016\n",
      "Epoch 1052/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1570e-05 - val_loss: 0.0016\n",
      "Epoch 1053/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1566e-05 - val_loss: 0.0016\n",
      "Epoch 1054/1200\n",
      "5/5 [==============================] - 0s 774us/step - loss: 1.1563e-05 - val_loss: 0.0016\n",
      "Epoch 1055/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1560e-05 - val_loss: 0.0016\n",
      "Epoch 1056/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1557e-05 - val_loss: 0.0016\n",
      "Epoch 1057/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1554e-05 - val_loss: 0.0016\n",
      "Epoch 1058/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1552e-05 - val_loss: 0.0016\n",
      "Epoch 1059/1200\n",
      "5/5 [==============================] - 0s 605us/step - loss: 1.1548e-05 - val_loss: 0.0016\n",
      "Epoch 1060/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1546e-05 - val_loss: 0.0016\n",
      "Epoch 1061/1200\n",
      "5/5 [==============================] - 0s 845us/step - loss: 1.1543e-05 - val_loss: 0.0016\n",
      "Epoch 1062/1200\n",
      "5/5 [==============================] - 0s 692us/step - loss: 1.1540e-05 - val_loss: 0.0016\n",
      "Epoch 1063/1200\n",
      "5/5 [==============================] - 0s 929us/step - loss: 1.1537e-05 - val_loss: 0.0016\n",
      "Epoch 1064/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1535e-05 - val_loss: 0.0016\n",
      "Epoch 1065/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1532e-05 - val_loss: 0.0016\n",
      "Epoch 1066/1200\n",
      "5/5 [==============================] - 0s 523us/step - loss: 1.1529e-05 - val_loss: 0.0016\n",
      "Epoch 1067/1200\n",
      "5/5 [==============================] - 0s 951us/step - loss: 1.1527e-05 - val_loss: 0.0016\n",
      "Epoch 1068/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1524e-05 - val_loss: 0.0016\n",
      "Epoch 1069/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1521e-05 - val_loss: 0.0016\n",
      "Epoch 1070/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1519e-05 - val_loss: 0.0016\n",
      "Epoch 1071/1200\n",
      "5/5 [==============================] - 0s 524us/step - loss: 1.1516e-05 - val_loss: 0.0016\n",
      "Epoch 1072/1200\n",
      "5/5 [==============================] - 0s 523us/step - loss: 1.1514e-05 - val_loss: 0.0016\n",
      "Epoch 1073/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1511e-05 - val_loss: 0.0016\n",
      "Epoch 1074/1200\n",
      "5/5 [==============================] - 0s 518us/step - loss: 1.1509e-05 - val_loss: 0.0016\n",
      "Epoch 1075/1200\n",
      "5/5 [==============================] - 0s 518us/step - loss: 1.1506e-05 - val_loss: 0.0016\n",
      "Epoch 1076/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1504e-05 - val_loss: 0.0016\n",
      "Epoch 1077/1200\n",
      "5/5 [==============================] - 0s 509us/step - loss: 1.1501e-05 - val_loss: 0.0016\n",
      "Epoch 1078/1200\n",
      "5/5 [==============================] - 0s 762us/step - loss: 1.1499e-05 - val_loss: 0.0016\n",
      "Epoch 1079/1200\n",
      "5/5 [==============================] - 0s 494us/step - loss: 1.1497e-05 - val_loss: 0.0016\n",
      "Epoch 1080/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1494e-05 - val_loss: 0.0016\n",
      "Epoch 1081/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1492e-05 - val_loss: 0.0016\n",
      "Epoch 1082/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1490e-05 - val_loss: 0.0016\n",
      "Epoch 1083/1200\n",
      "5/5 [==============================] - 0s 565us/step - loss: 1.1487e-05 - val_loss: 0.0016\n",
      "Epoch 1084/1200\n",
      "5/5 [==============================] - 0s 717us/step - loss: 1.1485e-05 - val_loss: 0.0016\n",
      "Epoch 1085/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1483e-05 - val_loss: 0.0016\n",
      "Epoch 1086/1200\n",
      "5/5 [==============================] - 0s 736us/step - loss: 1.1481e-05 - val_loss: 0.0016\n",
      "Epoch 1087/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1478e-05 - val_loss: 0.0016\n",
      "Epoch 1088/1200\n",
      "5/5 [==============================] - 0s 914us/step - loss: 1.1476e-05 - val_loss: 0.0016\n",
      "Epoch 1089/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1474e-05 - val_loss: 0.0016\n",
      "Epoch 1090/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1472e-05 - val_loss: 0.0016\n",
      "Epoch 1091/1200\n",
      "5/5 [==============================] - 0s 708us/step - loss: 1.1470e-05 - val_loss: 0.0016\n",
      "Epoch 1092/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1467e-05 - val_loss: 0.0016\n",
      "Epoch 1093/1200\n",
      "5/5 [==============================] - 0s 632us/step - loss: 1.1465e-05 - val_loss: 0.0016\n",
      "Epoch 1094/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1463e-05 - val_loss: 0.0016\n",
      "Epoch 1095/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1461e-05 - val_loss: 0.0016\n",
      "Epoch 1096/1200\n",
      "5/5 [==============================] - 0s 785us/step - loss: 1.1459e-05 - val_loss: 0.0016\n",
      "Epoch 1097/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1457e-05 - val_loss: 0.0016\n",
      "Epoch 1098/1200\n",
      "5/5 [==============================] - 0s 665us/step - loss: 1.1455e-05 - val_loss: 0.0016\n",
      "Epoch 1099/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1452e-05 - val_loss: 0.0016\n",
      "Epoch 1100/1200\n",
      "5/5 [==============================] - 0s 776us/step - loss: 1.1450e-05 - val_loss: 0.0016\n",
      "Epoch 1101/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.1448e-05 - val_loss: 0.0016\n",
      "Epoch 1102/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1446e-05 - val_loss: 0.0016\n",
      "Epoch 1103/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1444e-05 - val_loss: 0.0016\n",
      "Epoch 1104/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1442e-05 - val_loss: 0.0016\n",
      "Epoch 1105/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1440e-05 - val_loss: 0.0016\n",
      "Epoch 1106/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1438e-05 - val_loss: 0.0016\n",
      "Epoch 1107/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1436e-05 - val_loss: 0.0016\n",
      "Epoch 1108/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1434e-05 - val_loss: 0.0016\n",
      "Epoch 1109/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1432e-05 - val_loss: 0.0016\n",
      "Epoch 1110/1200\n",
      "5/5 [==============================] - 0s 908us/step - loss: 1.1430e-05 - val_loss: 0.0016\n",
      "Epoch 1111/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1428e-05 - val_loss: 0.0016\n",
      "Epoch 1112/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1426e-05 - val_loss: 0.0016\n",
      "Epoch 1113/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1424e-05 - val_loss: 0.0016\n",
      "Epoch 1114/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1422e-05 - val_loss: 0.0016\n",
      "Epoch 1115/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1420e-05 - val_loss: 0.0016\n",
      "Epoch 1116/1200\n",
      "5/5 [==============================] - 0s 630us/step - loss: 1.1418e-05 - val_loss: 0.0016\n",
      "Epoch 1117/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1416e-05 - val_loss: 0.0016\n",
      "Epoch 1118/1200\n",
      "5/5 [==============================] - 0s 679us/step - loss: 1.1414e-05 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1119/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1412e-05 - val_loss: 0.0016\n",
      "Epoch 1120/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1410e-05 - val_loss: 0.0016\n",
      "Epoch 1121/1200\n",
      "5/5 [==============================] - 0s 974us/step - loss: 1.1408e-05 - val_loss: 0.0016\n",
      "Epoch 1122/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1406e-05 - val_loss: 0.0016\n",
      "Epoch 1123/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1404e-05 - val_loss: 0.0016\n",
      "Epoch 1124/1200\n",
      "5/5 [==============================] - 0s 979us/step - loss: 1.1402e-05 - val_loss: 0.0016\n",
      "Epoch 1125/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1400e-05 - val_loss: 0.0016\n",
      "Epoch 1126/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1399e-05 - val_loss: 0.0016\n",
      "Epoch 1127/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1397e-05 - val_loss: 0.0016\n",
      "Epoch 1128/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1395e-05 - val_loss: 0.0016\n",
      "Epoch 1129/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1393e-05 - val_loss: 0.0016\n",
      "Epoch 1130/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1391e-05 - val_loss: 0.0016\n",
      "Epoch 1131/1200\n",
      "5/5 [==============================] - 0s 554us/step - loss: 1.1389e-05 - val_loss: 0.0016\n",
      "Epoch 1132/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1387e-05 - val_loss: 0.0016\n",
      "Epoch 1133/1200\n",
      "5/5 [==============================] - 0s 929us/step - loss: 1.1385e-05 - val_loss: 0.0016\n",
      "Epoch 1134/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1383e-05 - val_loss: 0.0016\n",
      "Epoch 1135/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1381e-05 - val_loss: 0.0016\n",
      "Epoch 1136/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1379e-05 - val_loss: 0.0016\n",
      "Epoch 1137/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1378e-05 - val_loss: 0.0016\n",
      "Epoch 1138/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1376e-05 - val_loss: 0.0016\n",
      "Epoch 1139/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1374e-05 - val_loss: 0.0016\n",
      "Epoch 1140/1200\n",
      "5/5 [==============================] - 0s 508us/step - loss: 1.1372e-05 - val_loss: 0.0016\n",
      "Epoch 1141/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1370e-05 - val_loss: 0.0016\n",
      "Epoch 1142/1200\n",
      "5/5 [==============================] - 0s 881us/step - loss: 1.1368e-05 - val_loss: 0.0016\n",
      "Epoch 1143/1200\n",
      "5/5 [==============================] - 0s 696us/step - loss: 1.1366e-05 - val_loss: 0.0016\n",
      "Epoch 1144/1200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 1.1364e-05 - val_loss: 0.0016\n",
      "Epoch 1145/1200\n",
      "5/5 [==============================] - 0s 789us/step - loss: 1.1362e-05 - val_loss: 0.0016\n",
      "Epoch 1146/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1360e-05 - val_loss: 0.0016\n",
      "Epoch 1147/1200\n",
      "5/5 [==============================] - 0s 854us/step - loss: 1.1359e-05 - val_loss: 0.0016\n",
      "Epoch 1148/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1357e-05 - val_loss: 0.0016\n",
      "Epoch 1149/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1355e-05 - val_loss: 0.0016\n",
      "Epoch 1150/1200\n",
      "5/5 [==============================] - 0s 562us/step - loss: 1.1353e-05 - val_loss: 0.0016\n",
      "Epoch 1151/1200\n",
      "5/5 [==============================] - 0s 695us/step - loss: 1.1351e-05 - val_loss: 0.0016\n",
      "Epoch 1152/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1349e-05 - val_loss: 0.0016\n",
      "Epoch 1153/1200\n",
      "5/5 [==============================] - 0s 716us/step - loss: 1.1347e-05 - val_loss: 0.0016\n",
      "Epoch 1154/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1345e-05 - val_loss: 0.0016\n",
      "Epoch 1155/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1343e-05 - val_loss: 0.0016\n",
      "Epoch 1156/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1342e-05 - val_loss: 0.0016\n",
      "Epoch 1157/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1340e-05 - val_loss: 0.0016\n",
      "Epoch 1158/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1338e-05 - val_loss: 0.0016\n",
      "Epoch 1159/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1336e-05 - val_loss: 0.0016\n",
      "Epoch 1160/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1334e-05 - val_loss: 0.0016\n",
      "Epoch 1161/1200\n",
      "5/5 [==============================] - 0s 909us/step - loss: 1.1332e-05 - val_loss: 0.0016\n",
      "Epoch 1162/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1330e-05 - val_loss: 0.0016\n",
      "Epoch 1163/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1328e-05 - val_loss: 0.0016\n",
      "Epoch 1164/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1327e-05 - val_loss: 0.0016\n",
      "Epoch 1165/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1325e-05 - val_loss: 0.0016\n",
      "Epoch 1166/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1323e-05 - val_loss: 0.0016\n",
      "Epoch 1167/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1321e-05 - val_loss: 0.0016\n",
      "Epoch 1168/1200\n",
      "5/5 [==============================] - 0s 935us/step - loss: 1.1319e-05 - val_loss: 0.0016\n",
      "Epoch 1169/1200\n",
      "5/5 [==============================] - 0s 671us/step - loss: 1.1317e-05 - val_loss: 0.0016\n",
      "Epoch 1170/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1315e-05 - val_loss: 0.0016\n",
      "Epoch 1171/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1313e-05 - val_loss: 0.0016\n",
      "Epoch 1172/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1312e-05 - val_loss: 0.0016\n",
      "Epoch 1173/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1310e-05 - val_loss: 0.0016\n",
      "Epoch 1174/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1308e-05 - val_loss: 0.0016\n",
      "Epoch 1175/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1306e-05 - val_loss: 0.0016\n",
      "Epoch 1176/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1304e-05 - val_loss: 0.0016\n",
      "Epoch 1177/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1302e-05 - val_loss: 0.0016\n",
      "Epoch 1178/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1300e-05 - val_loss: 0.0016\n",
      "Epoch 1179/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1299e-05 - val_loss: 0.0016\n",
      "Epoch 1180/1200\n",
      "5/5 [==============================] - 0s 930us/step - loss: 1.1297e-05 - val_loss: 0.0016\n",
      "Epoch 1181/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1295e-05 - val_loss: 0.0016\n",
      "Epoch 1182/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1293e-05 - val_loss: 0.0016\n",
      "Epoch 1183/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1291e-05 - val_loss: 0.0016\n",
      "Epoch 1184/1200\n",
      "5/5 [==============================] - 0s 957us/step - loss: 1.1289e-05 - val_loss: 0.0016\n",
      "Epoch 1185/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1287e-05 - val_loss: 0.0016\n",
      "Epoch 1186/1200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1285e-05 - val_loss: 0.0016\n",
      "Epoch 1187/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1283e-05 - val_loss: 0.0016\n",
      "Epoch 1188/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1282e-05 - val_loss: 0.0016\n",
      "Epoch 1189/1200\n",
      "5/5 [==============================] - 0s 613us/step - loss: 1.1280e-05 - val_loss: 0.0016\n",
      "Epoch 1190/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1278e-05 - val_loss: 0.0016\n",
      "Epoch 1191/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1276e-05 - val_loss: 0.0016\n",
      "Epoch 1192/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1274e-05 - val_loss: 0.0016\n",
      "Epoch 1193/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1272e-05 - val_loss: 0.0016\n",
      "Epoch 1194/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1270e-05 - val_loss: 0.0016\n",
      "Epoch 1195/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1268e-05 - val_loss: 0.0016\n",
      "Epoch 1196/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1267e-05 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1197/1200\n",
      "5/5 [==============================] - 0s 736us/step - loss: 1.1265e-05 - val_loss: 0.0016\n",
      "Epoch 1198/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1263e-05 - val_loss: 0.0016\n",
      "Epoch 1199/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1261e-05 - val_loss: 0.0016\n",
      "Epoch 1200/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1259e-05 - val_loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model4.fit(X, y, epochs=1200, validation_data=(valX, valY), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit model : This can be diagnosed from a plot where the train loss slopes down and the validation loss slopes down, hits an inflection point, and starts to slope up again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "pyplot.plot(history.history[ 'loss' ][500:])\n",
    "pyplot.plot(history.history[ 'val_loss' ][500:])\n",
    "pyplot.title( 'model train vs validation loss' )\n",
    "pyplot.ylabel( 'loss' )\n",
    "pyplot.xlabel( 'epoch' )\n",
    "pyplot.legend([ 'train' , 'validation' ], loc= 'upper right' )\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this case the model training could be stopped at inflection point. Alternately, the number of training examples could be increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 367ms/step - loss: 0.1262 - val_loss: 0.7743\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.1251 - val_loss: 0.7699\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.7652\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.1226 - val_loss: 0.7604\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 605us/step - loss: 0.1212 - val_loss: 0.7556\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 842us/step - loss: 0.1199 - val_loss: 0.7507\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 884us/step - loss: 0.1185 - val_loss: 0.7458\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 640us/step - loss: 0.1172 - val_loss: 0.7409\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1158 - val_loss: 0.7360\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 873us/step - loss: 0.1145 - val_loss: 0.7311\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 862us/step - loss: 0.1132 - val_loss: 0.7262\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 716us/step - loss: 0.1118 - val_loss: 0.7213\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1105 - val_loss: 0.7165\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1092 - val_loss: 0.7117\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1079 - val_loss: 0.7070\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 526us/step - loss: 0.1067 - val_loss: 0.7022\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 841us/step - loss: 0.1054 - val_loss: 0.6975\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1041 - val_loss: 0.6929\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1029 - val_loss: 0.6882\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 859us/step - loss: 0.1017 - val_loss: 0.6836\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1005 - val_loss: 0.6791\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0993 - val_loss: 0.6745\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.6700\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 842us/step - loss: 0.0969 - val_loss: 0.6656\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 662us/step - loss: 0.0957 - val_loss: 0.6611\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.6567\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.6523\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.6480\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.6437\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.6394\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 527us/step - loss: 0.0890 - val_loss: 0.6352\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 767us/step - loss: 0.0879 - val_loss: 0.6310\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0868 - val_loss: 0.6268\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.6226\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.6185\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.6144\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 824us/step - loss: 0.0826 - val_loss: 0.6104\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.6063\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.6023\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.5983\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 629us/step - loss: 0.0786 - val_loss: 0.5944\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.5904\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.5865\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.5827\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.5788\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.5750\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.5711\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.5673\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.5636\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.5598\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.5561\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 780us/step - loss: 0.0684 - val_loss: 0.5524\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 972us/step - loss: 0.0675 - val_loss: 0.5487\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.5450\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.5414\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.5377\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.5341\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.5305\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.5269\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.5233\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.5198\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 645us/step - loss: 0.0600 - val_loss: 0.5163\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.5128\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.5092\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.5057\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.5023\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 815us/step - loss: 0.0562 - val_loss: 0.4988\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.4954\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.4919\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.4885\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0532 - val_loss: 0.4851\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.4817\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.4783\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0510 - val_loss: 0.4749\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0503 - val_loss: 0.4715\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.4682\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0490 - val_loss: 0.4648\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.4615\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.4581\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.4548\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.4515\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.4482\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 512us/step - loss: 0.0450 - val_loss: 0.4450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 971us/step - loss: 0.0443 - val_loss: 0.4417\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0437 - val_loss: 0.4384\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.4352\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.4320\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 693us/step - loss: 0.0419 - val_loss: 0.4287\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.4255\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 658us/step - loss: 0.0407 - val_loss: 0.4223\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 867us/step - loss: 0.0401 - val_loss: 0.4191\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 573us/step - loss: 0.0395 - val_loss: 0.4160\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0389 - val_loss: 0.4128\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.4096\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.4065\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 563us/step - loss: 0.0373 - val_loss: 0.4034\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.4003\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.0362 - val_loss: 0.3972\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0357 - val_loss: 0.3941\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.3910\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 690us/step - loss: 0.0346 - val_loss: 0.3880\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.3849\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0336 - val_loss: 0.3819\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3789\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.3759\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 547us/step - loss: 0.0322 - val_loss: 0.3729\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.3699\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.3670\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 656us/step - loss: 0.0308 - val_loss: 0.3641\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0304 - val_loss: 0.3612\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.3582\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.3554\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.3525\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.3497\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.3468\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.3440\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.3412\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.3384\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.3357\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.3329\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.3302\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.3275\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.3248\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.3222\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.3195\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 540us/step - loss: 0.0243 - val_loss: 0.3169\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.3143\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 872us/step - loss: 0.0237 - val_loss: 0.3117\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0234 - val_loss: 0.3092\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 698us/step - loss: 0.0231 - val_loss: 0.3066\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.0228 - val_loss: 0.3041\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.3016\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.2992\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.2967\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.2943\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.2919\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.2895\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.2872\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.2849\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 618us/step - loss: 0.0205 - val_loss: 0.2826\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.2803\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.2780\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.0199 - val_loss: 0.2758\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.2736\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.2714\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.2693\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.2671\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 668us/step - loss: 0.0189 - val_loss: 0.2650\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.2630\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.2609\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.2589\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.2569\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 692us/step - loss: 0.0181 - val_loss: 0.2549\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 993us/step - loss: 0.0179 - val_loss: 0.2530\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.2510\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0177 - val_loss: 0.2491\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.2473\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.2454\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.2436\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.2418\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.2400\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2383\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2366\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.2349\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.2332\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 972us/step - loss: 0.0165 - val_loss: 0.2316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.2300\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 898us/step - loss: 0.0163 - val_loss: 0.2284\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.2268\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.2253\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.2238\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.2223\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.2208\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.0158 - val_loss: 0.2194\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.2180\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.2166\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.2152\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 555us/step - loss: 0.0155 - val_loss: 0.2139\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.2126\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.2113\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.2100\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.2087\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.2075\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.2063\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.2051\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 765us/step - loss: 0.0150 - val_loss: 0.2039\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 742us/step - loss: 0.0150 - val_loss: 0.2028\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.2017\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.2006\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1995\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.1984\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.1974\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0147 - val_loss: 0.1964\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1954\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.1944\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.1934\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.1925\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1915\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.1906\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1897\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1888\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 818us/step - loss: 0.0144 - val_loss: 0.1880\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1871\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1863\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0143 - val_loss: 0.1854\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1846\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 665us/step - loss: 0.0142 - val_loss: 0.1838\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1831\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1823\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1815\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1808\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1801\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1793\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 735us/step - loss: 0.0140 - val_loss: 0.1786\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1779\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1773\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1766\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1759\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1753\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1746\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1740\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.1734\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1728\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1722\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 653us/step - loss: 0.0136 - val_loss: 0.1716\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1710\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.0136 - val_loss: 0.1704\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1698\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1692\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1687\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.0135 - val_loss: 0.1681\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1676\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 757us/step - loss: 0.0134 - val_loss: 0.1670\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1665\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1660\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1654\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1649\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.1644\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1639\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1634\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1629\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1624\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1619\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 845us/step - loss: 0.0131 - val_loss: 0.1614\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.1609\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1604\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1599\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1594\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1585\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1580\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1575\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1571\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0128 - val_loss: 0.1566\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1561\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1557\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1552\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 690us/step - loss: 0.0127 - val_loss: 0.1547\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1543\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1538\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1534\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1529\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.0125 - val_loss: 0.1525\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1520\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1516\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1511\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1507\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.0124 - val_loss: 0.1502\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1498\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1493\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1489\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1484\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1480\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.1476\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 627us/step - loss: 0.0121 - val_loss: 0.1471\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1467\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1462\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1458\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1453\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1449\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1445\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.0119 - val_loss: 0.1440\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1436\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1431\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 676us/step - loss: 0.0118 - val_loss: 0.1427\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1423\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1418\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1414\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1409\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1405\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1400\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1396\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 821us/step - loss: 0.0116 - val_loss: 0.1392\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1387\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.1383\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1378\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1374\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1370\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 779us/step - loss: 0.0114 - val_loss: 0.1365\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1361\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 386ms/step - loss: 0.0975 - val_loss: 0.5654\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0966 - val_loss: 0.5622\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0957 - val_loss: 0.5587\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 769us/step - loss: 0.0947 - val_loss: 0.5552\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 975us/step - loss: 0.0936 - val_loss: 0.5516\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.5479\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.5442\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0904 - val_loss: 0.5405\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.0893 - val_loss: 0.5368\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.0883 - val_loss: 0.5331\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 509us/step - loss: 0.0872 - val_loss: 0.5293\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 867us/step - loss: 0.0861 - val_loss: 0.5256\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.0850 - val_loss: 0.5218\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.0840 - val_loss: 0.5181\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 712us/step - loss: 0.0829 - val_loss: 0.5143\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 779us/step - loss: 0.0819 - val_loss: 0.5105\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.5068\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 819us/step - loss: 0.0798 - val_loss: 0.5030\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.0787 - val_loss: 0.4992\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0777 - val_loss: 0.4955\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 701us/step - loss: 0.0766 - val_loss: 0.4917\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 806us/step - loss: 0.0756 - val_loss: 0.4880\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.4842\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.4805\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0725 - val_loss: 0.4767\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.4730\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 710us/step - loss: 0.0705 - val_loss: 0.4692\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.4655\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.0685 - val_loss: 0.4617\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 552us/step - loss: 0.0676 - val_loss: 0.4580\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.4543\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.4506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 660us/step - loss: 0.0647 - val_loss: 0.4469\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.4432\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 658us/step - loss: 0.0628 - val_loss: 0.4395\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 713us/step - loss: 0.0618 - val_loss: 0.4358\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.4321\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0600 - val_loss: 0.4284\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 551us/step - loss: 0.0590 - val_loss: 0.4247\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 937us/step - loss: 0.0581 - val_loss: 0.4210\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 859us/step - loss: 0.0572 - val_loss: 0.4174\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.4137\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.0554 - val_loss: 0.4101\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 680us/step - loss: 0.0545 - val_loss: 0.4065\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 530us/step - loss: 0.0537 - val_loss: 0.4028\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 516us/step - loss: 0.0528 - val_loss: 0.3992\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 910us/step - loss: 0.0519 - val_loss: 0.3956\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.0511 - val_loss: 0.3920\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 746us/step - loss: 0.0502 - val_loss: 0.3885\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 786us/step - loss: 0.0494 - val_loss: 0.3849\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 790us/step - loss: 0.0486 - val_loss: 0.3813\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0478 - val_loss: 0.3778\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 491us/step - loss: 0.0470 - val_loss: 0.3742\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.3707\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.3672\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.0446 - val_loss: 0.3636\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.3601\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.3567\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.3532\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 933us/step - loss: 0.0415 - val_loss: 0.3497\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.3463\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.3429\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.3394\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.3360\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.3327\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.3293\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.3259\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.3226\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.3193\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.3160\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.3127\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.3094\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.3062\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.3029\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.2997\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.2965\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.2933\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.2902\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 771us/step - loss: 0.0290 - val_loss: 0.2871\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.2839\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.2808\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 948us/step - loss: 0.0273 - val_loss: 0.2778\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.2747\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.2717\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.2687\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.2657\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 664us/step - loss: 0.0247 - val_loss: 0.2628\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.2598\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 655us/step - loss: 0.0237 - val_loss: 0.2569\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.2540\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.2512\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.2483\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.2455\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.2427\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.2400\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 882us/step - loss: 0.0206 - val_loss: 0.2372\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.2345\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 779us/step - loss: 0.0198 - val_loss: 0.2319\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.2292\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0191 - val_loss: 0.2266\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.2240\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0183 - val_loss: 0.2214\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.2189\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.2164\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.2139\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.2114\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 720us/step - loss: 0.0167 - val_loss: 0.2090\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.2066\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.0161 - val_loss: 0.2043\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.2019\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.1996\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.0152 - val_loss: 0.1973\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.1951\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.1929\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1885\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1864\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1843\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1823\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1802\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1782\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1762\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1743\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1724\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 765us/step - loss: 0.0124 - val_loss: 0.1705\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1687\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.0121 - val_loss: 0.1668\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1651\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 850us/step - loss: 0.0117 - val_loss: 0.1633\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1616\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1599\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0113 - val_loss: 0.1582\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 523us/step - loss: 0.0112 - val_loss: 0.1565\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1549\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1534\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1518\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1503\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1488\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1473\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1459\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1445\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1431\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1417\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1404\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1391\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1378\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1366\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1353\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1341\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1330\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1318\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 594us/step - loss: 0.0095 - val_loss: 0.1307\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1296\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 628us/step - loss: 0.0094 - val_loss: 0.1285\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1275\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 724us/step - loss: 0.0093 - val_loss: 0.1264\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1254\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1244\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 867us/step - loss: 0.0091 - val_loss: 0.1235\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1225\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1216\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1207\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1198\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1190\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1181\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1173\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1165\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 683us/step - loss: 0.0088 - val_loss: 0.1157\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 966us/step - loss: 0.0087 - val_loss: 0.1149\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 857us/step - loss: 0.0087 - val_loss: 0.1142\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 772us/step - loss: 0.0087 - val_loss: 0.1134\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.1127\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1120\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0086 - val_loss: 0.1113\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.1107\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1100\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 532us/step - loss: 0.0085 - val_loss: 0.1093\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.1087\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.1081\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1075\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1069\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.1063\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1058\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 987us/step - loss: 0.0083 - val_loss: 0.1052\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1047\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1041\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1036\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1031\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1026\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1021\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.1016\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1011\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1007\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1002\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0998\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0993\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 701us/step - loss: 0.0081 - val_loss: 0.0989\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 967us/step - loss: 0.0080 - val_loss: 0.0985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0981\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0976\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 778us/step - loss: 0.0080 - val_loss: 0.0972\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0968\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 845us/step - loss: 0.0079 - val_loss: 0.0964\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0960\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0957\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0953\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0949\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 811us/step - loss: 0.0078 - val_loss: 0.0945\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 854us/step - loss: 0.0078 - val_loss: 0.0942\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0938\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0935\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 537us/step - loss: 0.0077 - val_loss: 0.0931\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0927\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.0077 - val_loss: 0.0924\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0921\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0917\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 778us/step - loss: 0.0076 - val_loss: 0.0914\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0910\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 719us/step - loss: 0.0076 - val_loss: 0.0907\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0904\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0901\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0897\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0894\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0891\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0888\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0884\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0881\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 712us/step - loss: 0.0074 - val_loss: 0.0878\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0875\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 650us/step - loss: 0.0074 - val_loss: 0.0872\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0869\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0866\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 620us/step - loss: 0.0073 - val_loss: 0.0863\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0859\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0856\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0853\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 950us/step - loss: 0.0072 - val_loss: 0.0850\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0847\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0844\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0841\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0838\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0835\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0832\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0829\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0826\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 832us/step - loss: 0.0070 - val_loss: 0.0823\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 830us/step - loss: 0.0070 - val_loss: 0.0820\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0817\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0814\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0811\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0808\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0805\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0802\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0799\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0796\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0793\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 657us/step - loss: 0.0068 - val_loss: 0.0790\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0787\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0784\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 962us/step - loss: 0.0067 - val_loss: 0.0781\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0778\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0775\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 910us/step - loss: 0.0067 - val_loss: 0.0772\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 958us/step - loss: 0.0066 - val_loss: 0.0769\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0766\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0763\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0760\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0757\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0754\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0751\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0748\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0745\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0742\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0064 - val_loss: 0.0739\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0736\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0733\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0730\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0727\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 651us/step - loss: 0.0063 - val_loss: 0.0724\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0721\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 616us/step - loss: 0.0062 - val_loss: 0.0715\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0712\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0709\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0062 - val_loss: 0.0706\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 915us/step - loss: 0.0061 - val_loss: 0.0703\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0700\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.0061 - val_loss: 0.0697\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0694\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0691\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0688\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 580us/step - loss: 0.0060 - val_loss: 0.0685\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0682\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 793us/step - loss: 0.0060 - val_loss: 0.0679\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0676\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0673\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0670\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0667\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0664\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0661\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 416ms/step - loss: 0.1117 - val_loss: 0.6697\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.1105 - val_loss: 0.6648\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1092 - val_loss: 0.6591\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1076 - val_loss: 0.6538\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 641us/step - loss: 0.1061 - val_loss: 0.6485\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1046 - val_loss: 0.6430\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 707us/step - loss: 0.1031 - val_loss: 0.6376\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 597us/step - loss: 0.1016 - val_loss: 0.6322\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1001 - val_loss: 0.6267\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 560us/step - loss: 0.0986 - val_loss: 0.6213\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 639us/step - loss: 0.0971 - val_loss: 0.6159\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.0957 - val_loss: 0.6105\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0942 - val_loss: 0.6051\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.5998\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.5944\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 940us/step - loss: 0.0899 - val_loss: 0.5892\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.5839\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 723us/step - loss: 0.0871 - val_loss: 0.5787\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.0857 - val_loss: 0.5735\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.5683\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.5632\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.5581\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 866us/step - loss: 0.0804 - val_loss: 0.5531\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.0791 - val_loss: 0.5480\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.0778 - val_loss: 0.5430\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0765 - val_loss: 0.5381\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.0753 - val_loss: 0.5332\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 945us/step - loss: 0.0740 - val_loss: 0.5283\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.5235\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 682us/step - loss: 0.0716 - val_loss: 0.5187\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.5139\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.5092\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.5045\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.4998\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0658 - val_loss: 0.4952\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 911us/step - loss: 0.0647 - val_loss: 0.4906\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.4860\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 633us/step - loss: 0.0625 - val_loss: 0.4815\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0614 - val_loss: 0.4770\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.4726\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.4681\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.4638\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.4594\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0562 - val_loss: 0.4551\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 885us/step - loss: 0.0552 - val_loss: 0.4508\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.4465\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.4423\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.4381\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0514 - val_loss: 0.4340\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.4299\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.4258\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.4217\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.4177\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0470 - val_loss: 0.4137\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.0461 - val_loss: 0.4097\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.4057\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.4018\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.3979\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.3941\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.3903\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.3865\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.3827\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.3790\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.3753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.3716\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0376 - val_loss: 0.3680\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.3643\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.3608\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.0355 - val_loss: 0.3572\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.3537\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 590us/step - loss: 0.0342 - val_loss: 0.3502\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.3467\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.3433\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0323 - val_loss: 0.3399\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0317 - val_loss: 0.3365\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.3332\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0306 - val_loss: 0.3299\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.3266\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 741us/step - loss: 0.0295 - val_loss: 0.3234\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 669us/step - loss: 0.0289 - val_loss: 0.3202\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 759us/step - loss: 0.0284 - val_loss: 0.3170\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 634us/step - loss: 0.0279 - val_loss: 0.3138\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.3107\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 625us/step - loss: 0.0268 - val_loss: 0.3076\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.3046\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 645us/step - loss: 0.0259 - val_loss: 0.3015\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.2985\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.2956\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.0245 - val_loss: 0.2926\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.0241 - val_loss: 0.2897\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.0237 - val_loss: 0.2868\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 546us/step - loss: 0.0232 - val_loss: 0.2840\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.2812\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.2784\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.2756\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0217 - val_loss: 0.2729\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.0213 - val_loss: 0.2702\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.2676\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.2650\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 956us/step - loss: 0.0203 - val_loss: 0.2624\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.2598\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.2573\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 614us/step - loss: 0.0193 - val_loss: 0.2548\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.2523\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.2499\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.2475\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.2451\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.2427\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.2404\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 827us/step - loss: 0.0174 - val_loss: 0.2382\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.2359\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2337\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.2315\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 728us/step - loss: 0.0165 - val_loss: 0.2293\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.2272\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.2251\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.2231\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 941us/step - loss: 0.0157 - val_loss: 0.2210\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.2190\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2171\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.2151\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.2132\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.2113\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 835us/step - loss: 0.0146 - val_loss: 0.2095\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.2076\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.2058\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.2041\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0140 - val_loss: 0.2023\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 805us/step - loss: 0.0139 - val_loss: 0.2006\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1990\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1973\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1957\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1941\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 856us/step - loss: 0.0133 - val_loss: 0.1925\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1910\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0131 - val_loss: 0.1895\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1880\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 686us/step - loss: 0.0129 - val_loss: 0.1865\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1851\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1837\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1823\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1809\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1796\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1783\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1770\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1757\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 804us/step - loss: 0.0121 - val_loss: 0.1733\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1721\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.1709\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1698\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1686\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1675\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.0118 - val_loss: 0.1664\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1654\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.0117 - val_loss: 0.1643\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1633\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1623\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 604us/step - loss: 0.0115 - val_loss: 0.1613\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1603\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 531us/step - loss: 0.0114 - val_loss: 0.1594\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1585\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1575\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.1566\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1558\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1549\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1541\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1532\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1524\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1516\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0111 - val_loss: 0.1508\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1500\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0110 - val_loss: 0.1493\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1485\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1478\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.1471\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1464\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1457\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1450\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1443\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1437\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1430\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1424\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1418\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 648us/step - loss: 0.0106 - val_loss: 0.1412\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1405\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1400\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1394\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1388\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1382\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1376\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1371\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1365\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1360\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1355\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1349\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1344\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1339\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 722us/step - loss: 0.0102 - val_loss: 0.1334\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1329\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.1324\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1319\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1314\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1310\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 892us/step - loss: 0.0101 - val_loss: 0.1305\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1300\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1295\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1291\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1286\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1282\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1277\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1273\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1268\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 655us/step - loss: 0.0098 - val_loss: 0.1264\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1260\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1255\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.0097 - val_loss: 0.1251\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1247\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.0097 - val_loss: 0.1243\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.1239\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1234\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 846us/step - loss: 0.0096 - val_loss: 0.1230\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 686us/step - loss: 0.0096 - val_loss: 0.1226\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1222\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1218\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 845us/step - loss: 0.0095 - val_loss: 0.1214\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.0095 - val_loss: 0.1210\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0094 - val_loss: 0.1206\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1202\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 936us/step - loss: 0.0094 - val_loss: 0.1194\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1190\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1186\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 718us/step - loss: 0.0093 - val_loss: 0.1182\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 677us/step - loss: 0.0092 - val_loss: 0.1178\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 757us/step - loss: 0.0092 - val_loss: 0.1174\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 783us/step - loss: 0.0092 - val_loss: 0.1170\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.0092 - val_loss: 0.1166\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1162\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.1158\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.0091 - val_loss: 0.1154\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1151\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1147\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 958us/step - loss: 0.0090 - val_loss: 0.1143\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1139\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1135\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1131\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1128\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1124\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.1120\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1116\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1112\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.1109\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1105\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1101\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1097\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1093\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1090\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1086\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1082\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1078\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.1075\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1071\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1067\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.1063\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 822us/step - loss: 0.0084 - val_loss: 0.1059\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1056\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1052\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1048\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 839us/step - loss: 0.0083 - val_loss: 0.1044\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.1041\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1037\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1033\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1030\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1026\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.1022\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.1018\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1015\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 588us/step - loss: 0.0081 - val_loss: 0.1011\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.1007\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.1003\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.1000\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0996\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0992\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0989\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0985\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0981\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0977\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0974\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0970\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0966\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0963\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0959\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 613us/step - loss: 0.0077 - val_loss: 0.0955\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0951\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0948\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0944\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0940\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0937\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0933\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 3s 534ms/step - loss: 0.1116 - val_loss: 0.6650\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.1105 - val_loss: 0.6608\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.1093 - val_loss: 0.6564\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 734us/step - loss: 0.1081 - val_loss: 0.6518\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1067 - val_loss: 0.6472\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1054 - val_loss: 0.6425\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 731us/step - loss: 0.1041 - val_loss: 0.6378\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.6331\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.1014 - val_loss: 0.6284\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1001 - val_loss: 0.6237\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.6190\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 671us/step - loss: 0.0975 - val_loss: 0.6144\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0962 - val_loss: 0.6097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0949 - val_loss: 0.6051\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 675us/step - loss: 0.0936 - val_loss: 0.6004\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.5958\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 570us/step - loss: 0.0911 - val_loss: 0.5912\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 653us/step - loss: 0.0898 - val_loss: 0.5866\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 607us/step - loss: 0.0886 - val_loss: 0.5821\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 838us/step - loss: 0.0873 - val_loss: 0.5775\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.5730\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.5685\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 768us/step - loss: 0.0837 - val_loss: 0.5641\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.5596\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0813 - val_loss: 0.5552\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.5508\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.0790 - val_loss: 0.5464\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.5421\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.5378\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.5335\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 700us/step - loss: 0.0745 - val_loss: 0.5292\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0734 - val_loss: 0.5249\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.5207\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.5165\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 693us/step - loss: 0.0702 - val_loss: 0.5123\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 567us/step - loss: 0.0691 - val_loss: 0.5081\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 923us/step - loss: 0.0681 - val_loss: 0.5040\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.0670 - val_loss: 0.4998\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.4957\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0650 - val_loss: 0.4916\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 623us/step - loss: 0.0640 - val_loss: 0.4876\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0630 - val_loss: 0.4835\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 536us/step - loss: 0.0620 - val_loss: 0.4795\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 568us/step - loss: 0.0611 - val_loss: 0.4755\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0601 - val_loss: 0.4715\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 543us/step - loss: 0.0591 - val_loss: 0.4675\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.4636\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 587us/step - loss: 0.0573 - val_loss: 0.4597\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.4557\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 643us/step - loss: 0.0555 - val_loss: 0.4518\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0546 - val_loss: 0.4480\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.4441\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.4403\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.4364\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0511 - val_loss: 0.4326\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 868us/step - loss: 0.0502 - val_loss: 0.4288\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.4251\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 609us/step - loss: 0.0485 - val_loss: 0.4213\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.4176\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.4138\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.4101\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.4064\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.4028\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.3991\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.3955\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.3919\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.3883\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.3847\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.3812\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.3776\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0387 - val_loss: 0.3741\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.3706\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.3671\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.3636\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.3602\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.3568\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.3533\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.3500\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.3466\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0328 - val_loss: 0.3433\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.3400\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.3366\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.3334\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0305 - val_loss: 0.3301\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.3269\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.3237\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 775us/step - loss: 0.0289 - val_loss: 0.3205\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.3173\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.3142\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 978us/step - loss: 0.0274 - val_loss: 0.3111\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.3080\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.3049\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.3019\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.2988\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.2958\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 830us/step - loss: 0.0245 - val_loss: 0.2929\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 955us/step - loss: 0.0241 - val_loss: 0.2899\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.2870\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 518us/step - loss: 0.0233 - val_loss: 0.2841\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.2813\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.2784\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.0221 - val_loss: 0.2756\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.2729\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.2701\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.2674\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.2647\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.2621\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.2594\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.2568\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.2543\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.2518\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.2492\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.2468\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 858us/step - loss: 0.0182 - val_loss: 0.2443\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.2419\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.2395\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.2372\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.2348\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.2326\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.2303\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.2281\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.2259\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.2237\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.2216\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.2195\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.2174\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.2154\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.2134\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.2114\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.2095\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 646us/step - loss: 0.0147 - val_loss: 0.2076\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2057\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.2038\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 679us/step - loss: 0.0143 - val_loss: 0.2020\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 729us/step - loss: 0.0142 - val_loss: 0.2002\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1985\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.1968\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 777us/step - loss: 0.0138 - val_loss: 0.1951\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1934\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.1918\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1902\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1886\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.1871\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1855\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1841\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1826\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1812\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.0129 - val_loss: 0.1798\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1784\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1771\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1758\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.1745\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1732\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.1720\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1708\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1696\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1684\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1673\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1662\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1651\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1640\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1630\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1619\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1609\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.1600\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1590\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.1581\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1571\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1562\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1554\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1545\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1537\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.0116 - val_loss: 0.1528\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1520\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1512\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1505\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1497\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1490\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1475\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1468\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1461\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1455\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1448\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1442\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1435\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1429\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 703us/step - loss: 0.0111 - val_loss: 0.1423\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1417\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1411\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1405\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 652us/step - loss: 0.0110 - val_loss: 0.1399\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1394\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 688us/step - loss: 0.0110 - val_loss: 0.1388\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 654us/step - loss: 0.0109 - val_loss: 0.1383\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1377\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 721us/step - loss: 0.0109 - val_loss: 0.1372\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1367\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1362\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1357\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.1352\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 899us/step - loss: 0.0108 - val_loss: 0.1347\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1342\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1337\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1332\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1328\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1323\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 939us/step - loss: 0.0106 - val_loss: 0.1319\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 628us/step - loss: 0.0106 - val_loss: 0.1314\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1310\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1305\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1301\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 573us/step - loss: 0.0105 - val_loss: 0.1296\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.0104 - val_loss: 0.1292\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 581us/step - loss: 0.0104 - val_loss: 0.1288\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 901us/step - loss: 0.0104 - val_loss: 0.1283\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1279\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1275\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 728us/step - loss: 0.0103 - val_loss: 0.1271\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 962us/step - loss: 0.0103 - val_loss: 0.1267\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 649us/step - loss: 0.0102 - val_loss: 0.1262\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1258\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 572us/step - loss: 0.0102 - val_loss: 0.1254\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 689us/step - loss: 0.0102 - val_loss: 0.1250\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 642us/step - loss: 0.0101 - val_loss: 0.1246\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0101 - val_loss: 0.1242\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0101 - val_loss: 0.1238\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1234\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1230\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1226\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1222\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1218\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1214\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1210\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1206\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1202\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1198\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1194\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1190\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1187\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1183\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.1179\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1175\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 911us/step - loss: 0.0096 - val_loss: 0.1171\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1167\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 830us/step - loss: 0.0096 - val_loss: 0.1163\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1159\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 642us/step - loss: 0.0095 - val_loss: 0.1155\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1152\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 927us/step - loss: 0.0094 - val_loss: 0.1148\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1144\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1140\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1136\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1132\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 985us/step - loss: 0.0093 - val_loss: 0.1128\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1124\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1121\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.1117\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1113\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.0092 - val_loss: 0.1109\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1105\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1097\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1093\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1089\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.1086\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1082\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1078\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1074\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 716us/step - loss: 0.0089 - val_loss: 0.1070\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.1066\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1062\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.0088 - val_loss: 0.1058\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1054\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1051\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1047\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1043\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1039\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1035\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1031\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 669us/step - loss: 0.0086 - val_loss: 0.1027\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1023\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1019\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1016\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1012\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1008\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1004\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1000\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0996\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0992\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0988\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0984\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0980\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0977\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.0973\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0969\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0965\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0961\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0957\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0953\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 422ms/step - loss: 0.1209 - val_loss: 0.7346\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 667us/step - loss: 0.1197 - val_loss: 0.7298\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 674us/step - loss: 0.1184 - val_loss: 0.7247\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.7194\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1155 - val_loss: 0.7141\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 696us/step - loss: 0.1140 - val_loss: 0.7087\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 639us/step - loss: 0.1125 - val_loss: 0.7034\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.6980\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 730us/step - loss: 0.1095 - val_loss: 0.6926\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 759us/step - loss: 0.1080 - val_loss: 0.6872\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 536us/step - loss: 0.1065 - val_loss: 0.6819\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1051 - val_loss: 0.6765\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 855us/step - loss: 0.1036 - val_loss: 0.6712\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.6659\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 956us/step - loss: 0.1007 - val_loss: 0.6606\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 575us/step - loss: 0.0993 - val_loss: 0.6554\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 589us/step - loss: 0.0979 - val_loss: 0.6502\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 610us/step - loss: 0.0965 - val_loss: 0.6450\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0951 - val_loss: 0.6398\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 578us/step - loss: 0.0938 - val_loss: 0.6347\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.6295\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 565us/step - loss: 0.0911 - val_loss: 0.6245\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 796us/step - loss: 0.0897 - val_loss: 0.6194\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 516us/step - loss: 0.0884 - val_loss: 0.6144\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 549us/step - loss: 0.0871 - val_loss: 0.6094\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.6044\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.0846 - val_loss: 0.5994\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.0833 - val_loss: 0.5945\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.5896\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.0808 - val_loss: 0.5847\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.5799\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 607us/step - loss: 0.0784 - val_loss: 0.5751\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.5703\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0760 - val_loss: 0.5656\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.5608\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0737 - val_loss: 0.5561\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0725 - val_loss: 0.5515\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.5468\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.5422\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 561us/step - loss: 0.0692 - val_loss: 0.5376\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.5331\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.5285\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0659 - val_loss: 0.5240\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.5195\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 683us/step - loss: 0.0639 - val_loss: 0.5151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.5107\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 687us/step - loss: 0.0618 - val_loss: 0.5063\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.5019\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.4975\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 892us/step - loss: 0.0588 - val_loss: 0.4932\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.4889\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 895us/step - loss: 0.0569 - val_loss: 0.4847\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.4805\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.4763\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.4721\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0533 - val_loss: 0.4680\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 759us/step - loss: 0.0524 - val_loss: 0.4638\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.4597\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.4556\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0498 - val_loss: 0.4516\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 817us/step - loss: 0.0490 - val_loss: 0.4475\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.4435\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0473 - val_loss: 0.4396\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0465 - val_loss: 0.4356\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 689us/step - loss: 0.0457 - val_loss: 0.4317\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.4278\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.4239\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.4201\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.4163\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 890us/step - loss: 0.0419 - val_loss: 0.4125\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.4087\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.4050\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.4012\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.3975\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.3939\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.3903\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 816us/step - loss: 0.0371 - val_loss: 0.3867\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.3831\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0359 - val_loss: 0.3795\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 763us/step - loss: 0.0352 - val_loss: 0.3760\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.3725\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.3690\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.3655\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.3621\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.3587\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.3554\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.3520\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 582us/step - loss: 0.0307 - val_loss: 0.3487\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.3454\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.3422\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.3389\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.3358\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 979us/step - loss: 0.0282 - val_loss: 0.3326\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 848us/step - loss: 0.0277 - val_loss: 0.3295\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.3263\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.3233\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.3202\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0260 - val_loss: 0.3172\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.3142\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.3113\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 795us/step - loss: 0.0248 - val_loss: 0.3083\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.3054\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.3026\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.2997\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.2969\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.2941\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.2914\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.2887\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.2860\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.2833\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.2807\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.2781\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0207 - val_loss: 0.2755\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 917us/step - loss: 0.0204 - val_loss: 0.2730\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.2705\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.2680\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 736us/step - loss: 0.0196 - val_loss: 0.2656\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.2632\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 595us/step - loss: 0.0191 - val_loss: 0.2608\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.2584\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 669us/step - loss: 0.0187 - val_loss: 0.2561\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 586us/step - loss: 0.0185 - val_loss: 0.2538\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.2516\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.2494\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 649us/step - loss: 0.0178 - val_loss: 0.2472\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0177 - val_loss: 0.2450\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.2429\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.2387\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2367\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2347\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.2327\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2308\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.2288\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 568us/step - loss: 0.0162 - val_loss: 0.2270\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.2251\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 548us/step - loss: 0.0159 - val_loss: 0.2233\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.2215\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.2197\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2180\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.2163\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2146\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.2129\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.2113\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.2097\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.2081\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.2066\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.2051\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2036\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.2021\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.2007\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.1993\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.1979\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1965\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1952\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1939\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1926\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1914\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1901\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1889\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1877\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1865\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1854\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 759us/step - loss: 0.0137 - val_loss: 0.1843\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 763us/step - loss: 0.0136 - val_loss: 0.1831\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.1821\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1810\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1799\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 927us/step - loss: 0.0134 - val_loss: 0.1789\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1779\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1769\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1760\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0132 - val_loss: 0.1750\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1741\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 535us/step - loss: 0.0132 - val_loss: 0.1732\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1723\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1714\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1705\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 672us/step - loss: 0.0130 - val_loss: 0.1697\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1688\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.1680\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1672\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1664\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.1656\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1649\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1641\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1634\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1626\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0127 - val_loss: 0.1619\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1612\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1605\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1598\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1592\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1585\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1579\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1572\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0124 - val_loss: 0.1566\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.1560\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1554\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1547\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1542\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1536\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1530\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1524\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1518\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1513\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1507\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1502\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 757us/step - loss: 0.0121 - val_loss: 0.1496\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1491\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 847us/step - loss: 0.0120 - val_loss: 0.1486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.1481\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1475\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1470\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1465\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1460\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1455\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1450\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1445\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 557us/step - loss: 0.0118 - val_loss: 0.1441\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1436\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.1431\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 710us/step - loss: 0.0117 - val_loss: 0.1426\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1421\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.1417\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 565us/step - loss: 0.0116 - val_loss: 0.1412\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 695us/step - loss: 0.0116 - val_loss: 0.1407\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 874us/step - loss: 0.0115 - val_loss: 0.1403\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1398\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 810us/step - loss: 0.0115 - val_loss: 0.1394\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0114 - val_loss: 0.1389\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 666us/step - loss: 0.0114 - val_loss: 0.1385\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1380\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1376\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1371\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0113 - val_loss: 0.1367\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1362\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 579us/step - loss: 0.0112 - val_loss: 0.1358\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.1354\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1349\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.0112 - val_loss: 0.1345\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 617us/step - loss: 0.0111 - val_loss: 0.1341\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1336\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.1332\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1328\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1323\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 978us/step - loss: 0.0110 - val_loss: 0.1319\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1315\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1310\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1306\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1302\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1298\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1293\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1289\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0108 - val_loss: 0.1285\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1281\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1276\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0107 - val_loss: 0.1272\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1268\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1264\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.1260\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1255\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1251\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 834us/step - loss: 0.0105 - val_loss: 0.1247\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1243\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1239\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1234\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.1230\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1226\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1222\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1218\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 611us/step - loss: 0.0103 - val_loss: 0.1214\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1209\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1205\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1201\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.1197\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.0101 - val_loss: 0.1193\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.0101 - val_loss: 0.1189\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 739us/step - loss: 0.0101 - val_loss: 0.1184\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1180\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 845us/step - loss: 0.0100 - val_loss: 0.1176\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.1172\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1168\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1164\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.1159\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0099 - val_loss: 0.1155\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 737us/step - loss: 0.0098 - val_loss: 0.1151\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1147\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 689us/step - loss: 0.0098 - val_loss: 0.1143\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1139\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1135\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1130\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1126\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1118\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1114\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1110\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.1106\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1101\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1097\n"
     ]
    }
   ],
   "source": [
    "# collect data across multiple repeats\n",
    "train = DataFrame()\n",
    "val = DataFrame()\n",
    "for i in range(5):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_shape=(1,1)))\n",
    "    model.add(Dense(1, activation= 'linear' ))\n",
    "    # compile model\n",
    "    model.compile(loss= 'mse' , optimizer= 'adam' )\n",
    "    X,y = get_train()\n",
    "    valX, valY = get_val()\n",
    "    # fit model\n",
    "    history = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "    # story history\n",
    "    train[str(i)] = history.history[ 'loss' ]\n",
    "    val[str(i)] = history.history[ 'val_loss' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss across multiple runs\n",
    "pyplot.plot(train, color= 'blue' , label= 'train' )\n",
    "pyplot.plot(val, color= 'orange' , label= 'validation' )\n",
    "pyplot.title( 'model train vs validation loss' )\n",
    "pyplot.ylabel( 'loss' )\n",
    "pyplot.xlabel( 'epoch' )\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the resulting plot we can see that the general trend of underfitting holds across 5 runs and is a stronger case for perhaps increasing the number of training epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting number of memory cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We cannot know the best number of memory cells for a given sequence prediction problem or LSTM architecture. You must test a suite of different memory cells in your LSTM hidden layers to see what works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try grid searching the number of memory cells by 100s, 10s, or finer. \n",
    "### Try using numbers of cells quoted in research papers.\n",
    "### Try randomly searching the number of cells between 1 and 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM model\n",
    "def fit_model(n_cells):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_cells, input_shape=(1,1)))\n",
    "    model.add(Dense(1, activation= 'linear' ))\n",
    "    # compile model\n",
    "    model.compile(loss= 'mse' , optimizer= 'adam' )\n",
    "    # fit model\n",
    "    X,y = get_train()\n",
    "    history = model.fit(X, y, epochs=500, shuffle=False, verbose=0)\n",
    "    # evaluate model\n",
    "    valX, valY = get_val()\n",
    "    loss = model.evaluate(valX, valY, verbose=0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scope of search\n",
    "params = [1, 5, 10]\n",
    "n_repeats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >1/5 param=1.000000, loss=0.196090\n",
      " >2/5 param=1.000000, loss=0.181114\n",
      " >3/5 param=1.000000, loss=0.156455\n",
      " >4/5 param=1.000000, loss=0.161929\n",
      " >5/5 param=1.000000, loss=0.381166\n",
      " >1/5 param=5.000000, loss=0.069449\n",
      " >2/5 param=5.000000, loss=0.069430\n",
      " >3/5 param=5.000000, loss=0.096187\n",
      " >4/5 param=5.000000, loss=0.043886\n",
      " >5/5 param=5.000000, loss=0.056022\n",
      " >1/5 param=10.000000, loss=0.038102\n",
      " >2/5 param=10.000000, loss=0.046268\n",
      " >3/5 param=10.000000, loss=0.027728\n",
      " >4/5 param=10.000000, loss=0.043540\n",
      " >5/5 param=10.000000, loss=0.011573\n"
     ]
    }
   ],
   "source": [
    "# grid search parameter values\n",
    "scores = DataFrame()\n",
    "for value in params:\n",
    "# repeat each experiment multiple times\n",
    "    loss_values = list()\n",
    "    for i in range(n_repeats):\n",
    "        loss = fit_model(value)\n",
    "        loss_values.append(loss)\n",
    "        print(' >%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "    # store results for this parameter\n",
    "    scores[str(value)] = loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1         5        10\n",
      "count  5.000000  5.000000  5.000000\n",
      "mean   0.215351  0.066995  0.033442\n",
      "std    0.094022  0.019484  0.014134\n",
      "min    0.156455  0.043886  0.011573\n",
      "25%    0.161929  0.056022  0.027728\n",
      "50%    0.181114  0.069430  0.038102\n",
      "75%    0.196090  0.069449  0.043540\n",
      "max    0.381166  0.096187  0.046268\n"
     ]
    }
   ],
   "source": [
    "# summary statistics of results\n",
    "print(scores.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# box and whisker plot of results\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarly we can also grid search no. of hidden layers in our model, try searching both (no. of memory cells and no. of hidden layers) together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other things to keep in mind and try diffrent options of them are :\n",
    "## Value Scaling\n",
    "### 1) Normalize Values. 2) Standardize Values.\n",
    "## Value Encoding\n",
    "### 1) Real-Value Encoding 2) Integer Encoding 3) One Hot Encoding \n",
    "## Stationarity\n",
    "### 1) Remove Trends 2) Remove Seasonality 3) Remove Variance\n",
    "## Input Sequence Length\n",
    "### The lengthof the input sequence also impacts the Backpropagation through time used to estimate the error gradient when updating the weights. It can have an effect on how quickly the model learns and what is learned.\n",
    "## Sequence model type\n",
    "### 1) One-to-one 2) One-to-many 3) Many-to-one 4) Many-to-many\n",
    "## Architecture\n",
    "### As we have seen, there are many LSTM architectures to choose from. Some architectures lend themselves to certain sequence prediction problems, although most are flexible enough that they may be adapted to your sequence prediction problems. Test your assumptions of architecture suitability. Evaluate the skill of each LSTM architecture listed in this book (and perhaps beyond) on your sequence prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization\n",
    "### The Keras LSTM layer uses the glorot uniform weight initialization by default. This weight initialization works well in general, but I have had great success using normal type weight initialization with LSTMs. Evaluate the e↵ect of di↵erent weight initialization schemes on your model skill. Keras o↵ers a great list of weight initialization schemes for you to try. At the very least, compare the skill of these four methods:\n",
    "#### random_uniform\n",
    "#### random_normal\n",
    "#### glorot_uniform\n",
    "#### glorot_normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "The activation function (technically the transfer function as it transfers the weighted activation\n",
    "of the neuron) is often fixed by the framing and scale of the input or output layers. For example,\n",
    "LSTMs use a sigmoid activation function for input and so inputs are often in the scale 0-1.\n",
    "The classification or regression nature of the sequence prediction problem determines the type\n",
    "of activation function to use in the output layer. Challenge the default of sigmoid activation\n",
    "function in the LSTM layers. Try other methods, perhaps in tandem with rescaling input values.\n",
    "### For example try:\n",
    "### 1) sigmoid 2) tanh 3) relu\n",
    "#### Further, challenge whether all LSTM layers in a stacked LSTM need to use the same activation function. In practice, I rarely see a model do better than using sigmoid, but this assumption should be confirmed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Algorithms\n",
    "A good default implementation of gradient descent is the Adam algorithm. This is because it\n",
    "automatically uses a custom learning rate for each parameter (weight) in the model, combining\n",
    "the best properties of the AdaGrad and RMSProp methods. Further, the implementation of\n",
    "Adam in Keras uses the best practice initial values for each of the configuration parameters.\n",
    "Nevertheless, challenge that Adam is the right gradient descent algorithm for your model.\n",
    "Evaluate the performance of models with different gradient descent algorithms. Some ideas of\n",
    "well performing modern algorithms include:\n",
    "Adam, RMSprop, Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "The learning rate controls how much to update the weights in response to the estimated gradient at the end of each batch. This can have a large impact on the trade-off between how quickly or how well the model learns the problem. Consider using the classical stochastic gradient descent (SGD) optimizer and explore different learning rate and momentum values. More than just searching values, you can evaluate regimes that vary the learning rate.\n",
    "#### Grid search learning rate values (e.g. 0.1, 0.001, 0.0001). \n",
    "#### Experiment with a learning rate that decays with the number of epochs (e.g. via callback). \n",
    "#### Experiment with updating a fit model with training runs with smaller and smaller learning rates.\n",
    "The learning rate is tightly coupled with the number of epochs (number of passes through the training samples). Generally, the smaller the learning rate (e.g. 0.0001)), the more training epochs will be required. This is a linear relationship so the reverse is true, where fewer epochs are required for larger learning rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM model\n",
    "def fit_model(n_batch):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_shape=(1,1)))\n",
    "    model.add(Dense(1, activation= 'linear' ))\n",
    "    # compile model\n",
    "    model.compile(loss= 'mse' , optimizer= 'adam' )\n",
    "    # fit model\n",
    "    X,y = get_train()\n",
    "    history = model.fit(X, y, epochs=500, shuffle=False, verbose=0, batch_size=n_batch)\n",
    "    # evaluate model\n",
    "    valX, valY = get_val()\n",
    "    loss = model.evaluate(valX, valY, verbose=0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define scope of search\n",
    "params = [1, 2, 3]\n",
    "n_repeats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1/5 param=1.000000, loss=0.001325\n",
      ">2/5 param=1.000000, loss=0.001362\n",
      ">3/5 param=1.000000, loss=0.001438\n",
      ">4/5 param=1.000000, loss=0.000782\n",
      ">5/5 param=1.000000, loss=0.000033\n",
      ">1/5 param=2.000000, loss=0.000293\n",
      ">2/5 param=2.000000, loss=0.000654\n",
      ">3/5 param=2.000000, loss=0.000203\n",
      ">4/5 param=2.000000, loss=0.001230\n",
      ">5/5 param=2.000000, loss=0.000444\n",
      ">1/5 param=3.000000, loss=0.002122\n",
      ">2/5 param=3.000000, loss=0.002735\n",
      ">3/5 param=3.000000, loss=0.000380\n",
      ">4/5 param=3.000000, loss=0.001651\n",
      ">5/5 param=3.000000, loss=0.001902\n"
     ]
    }
   ],
   "source": [
    "# grid search parameter values\n",
    "scores = DataFrame()\n",
    "for value in params:\n",
    "    # repeat each experiment multiple times\n",
    "    loss_values = list()\n",
    "    for i in range(n_repeats):\n",
    "        loss = fit_model(value)\n",
    "        loss_values.append(loss)\n",
    "        print( '>%d/%d param=%f, loss=%f' % (i+1, n_repeats, value, loss))\n",
    "    # store results for this parameter\n",
    "    scores[str(value)] = loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1         2         3\n",
      "count  5.000000  5.000000  5.000000\n",
      "mean   0.000988  0.000565  0.001758\n",
      "std    0.000594  0.000409  0.000869\n",
      "min    0.000033  0.000203  0.000380\n",
      "25%    0.000782  0.000293  0.001651\n",
      "50%    0.001325  0.000444  0.001902\n",
      "75%    0.001362  0.000654  0.002122\n",
      "max    0.001438  0.001230  0.002735\n"
     ]
    }
   ],
   "source": [
    "# summary statistics of results\n",
    "print(scores.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# box and whisker plot of results\n",
    "scores.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "## Early Stopping via Callback\n",
    "The number of training epochs can be very time consuming to tune. An alternative approach is\n",
    "to configure a large number of training epochs. Then setup something to check the performance\n",
    "of the model on train and validation datasets and stop training if it looks like the model is\n",
    "starting to over learn. As such, early stopping is a type of regularization to curb overfitting.\n",
    "You can experiment with early stopping in Keras with an EarlyStopping callback. It\n",
    "requires that you specify a few configuration parameters, such as the metric to monitor (e.g.\n",
    "val loss), the number of epochs over which no improvement in the monitored metric are\n",
    "observed (e.g. 100). A list of callbacks is provided to the fit() function when training the\n",
    "model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example:\n",
    "#### from keras.callbacks import EarlyStopping\n",
    "#### es = EarlyStopping(monitor= val_loss , min_delta=100)\n",
    "#### model.fit(..., callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
